{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: A/B Testing & Hypothesis Testing\n",
    "\n",
    "**Goal:** Master statistical hypothesis testing and A/B testing for marketing experiments.\n",
    "\n",
    "**Time Commitment:** ~1 hour per day √ó 7 days = 7 hours total\n",
    "\n",
    "**What You'll Learn:**\n",
    "- A/B test fundamentals and experimental design\n",
    "- Sample size calculations and power analysis\n",
    "- Two-proportion z-tests for conversion rates\n",
    "- Statistical vs practical significance\n",
    "- Multiple testing corrections\n",
    "- Sequential testing for faster decisions\n",
    "- Real marketing experiment design and analysis\n",
    "\n",
    "**Why This Matters:**\n",
    "As a Marketing Measurement Partner, A/B testing is your primary tool for:\n",
    "- Proving that creative changes improve performance\n",
    "- Optimizing landing pages and user experiences\n",
    "- Making data-driven decisions with confidence\n",
    "- Avoiding costly mistakes based on random noise\n",
    "- Calculating the ROI of optimization efforts\n",
    "\n",
    "A/B testing separates opinions from facts. Master it, and you'll drive millions in incremental revenue.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Day 50: A/B Test Fundamentals (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the scientific method applied to marketing\n",
    "- Learn the components of an A/B test\n",
    "- Formulate null and alternative hypotheses\n",
    "- Understand Type I and Type II errors\n",
    "\n",
    "### The Business Problem\n",
    "Your marketing team believes a new landing page design will increase conversion rates. Before rolling it out to all traffic, you need to prove it works with statistical rigor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: The A/B Testing Framework\n",
    "\n",
    "**Components of an A/B Test:**\n",
    "1. **Control (A)**: Current version (baseline)\n",
    "2. **Treatment (B)**: New version (variant)\n",
    "3. **Metric**: What you're measuring (e.g., conversion rate)\n",
    "4. **Hypothesis**: Prediction about the treatment's effect\n",
    "5. **Sample Size**: How many users in each group\n",
    "6. **Significance Level (Œ±)**: Risk of false positive (typically 0.05 or 5%)\n",
    "\n",
    "**Hypotheses:**\n",
    "- **Null Hypothesis (H‚ÇÄ)**: No difference between A and B\n",
    "- **Alternative Hypothesis (H‚ÇÅ)**: There is a difference\n",
    "\n",
    "**Decision Errors:**\n",
    "- **Type I Error (Œ±)**: False positive - declaring a winner when there's no real difference\n",
    "- **Type II Error (Œ≤)**: False negative - missing a real difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Landing page A/B test data\n",
    "test_data = pd.DataFrame({\n",
    "    'variant': ['Control', 'Treatment'],\n",
    "    'visitors': [10000, 10000],\n",
    "    'conversions': [350, 412]\n",
    "})\n",
    "\n",
    "# Calculate conversion rates\n",
    "test_data['conversion_rate'] = test_data['conversions'] / test_data['visitors']\n",
    "\n",
    "print(\"A/B Test Results:\")\n",
    "print(test_data)\n",
    "print(f\"\\nObserved Lift: {((test_data.loc[1, 'conversion_rate'] / test_data.loc[0, 'conversion_rate']) - 1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Try It: Calculate Relative and Absolute Lift\n",
    "\n",
    "Understanding different ways to measure improvement is crucial for communicating results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Given the test_data above:\n",
    "# 1. Calculate absolute lift (treatment_rate - control_rate)\n",
    "# 2. Calculate relative lift ((treatment_rate - control_rate) / control_rate)\n",
    "# 3. Which metric is more meaningful for business decisions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Statistical Significance\n",
    "\n",
    "Just observing a difference doesn't mean it's real. We need to account for random chance.\n",
    "\n",
    "**P-value**: The probability of seeing results this extreme (or more) if there's actually no difference.\n",
    "- If p < 0.05, we reject the null hypothesis (declare significance)\n",
    "- If p ‚â• 0.05, we fail to reject the null (insufficient evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the concept of p-value\n",
    "control_rate = test_data.loc[0, 'conversion_rate']\n",
    "treatment_rate = test_data.loc[1, 'conversion_rate']\n",
    "\n",
    "# Simulate what we'd see under the null hypothesis (no difference)\n",
    "null_distribution = np.random.binomial(10000, control_rate, size=10000) / 10000\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(null_distribution, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(treatment_rate, color='red', linestyle='--', linewidth=2, label=f'Treatment Rate: {treatment_rate:.4f}')\n",
    "plt.axvline(control_rate, color='blue', linestyle='--', linewidth=2, label=f'Control Rate: {control_rate:.4f}')\n",
    "plt.xlabel('Conversion Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Null Distribution: What We\\'d Expect by Random Chance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Treatment rate is {abs(treatment_rate - control_rate) / np.std(null_distribution):.2f} standard deviations from control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 1: Interpret Test Results\n",
    "\n",
    "You ran three different A/B tests. Interpret each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'test_name': ['Email Subject Line', 'Ad Creative', 'Pricing Page'],\n",
    "    'control_cvr': [0.025, 0.042, 0.105],\n",
    "    'treatment_cvr': [0.028, 0.045, 0.098],\n",
    "    'p_value': [0.023, 0.112, 0.086],\n",
    "    'sample_size_per_group': [50000, 20000, 8000]\n",
    "})\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# For each test:\n",
    "# 1. Calculate relative lift\n",
    "# 2. Determine if it's statistically significant (p < 0.05)\n",
    "# 3. Make a recommendation: Implement, Don't Implement, or Run Longer\n",
    "# 4. Explain your reasoning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Day 50 Mini-Project: Design Your First A/B Test\n",
    "\n",
    "Design a complete A/B test for a marketing scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: You want to test a new CTA button color on your product page\n",
    "# Current performance:\n",
    "# - Daily visitors: 5,000\n",
    "# - Current conversion rate: 4.0%\n",
    "# - Expected lift from new button: 10% relative improvement\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Design the test by specifying:\n",
    "# 1. Null hypothesis\n",
    "# 2. Alternative hypothesis  \n",
    "# 3. Primary metric\n",
    "# 4. Significance level (Œ±)\n",
    "# 5. Desired power (1 - Œ≤), typically 0.80\n",
    "# 6. Minimum detectable effect\n",
    "# 7. How you'll split traffic (50/50, 90/10, etc.)\n",
    "# 8. Any guardrail metrics you'll monitor\n",
    "#\n",
    "# Create a document/dict with your test plan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Day 50 Key Takeaways\n",
    "\n",
    "‚úÖ A/B testing applies the scientific method to marketing  \n",
    "‚úÖ Always formulate hypotheses before running tests  \n",
    "‚úÖ Statistical significance prevents false positives  \n",
    "‚úÖ P-value measures probability of results under null hypothesis  \n",
    "‚úÖ Consider both Type I and Type II errors  \n",
    "\n",
    "**Next:** Tomorrow we'll calculate required sample sizes!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Day 51: Sample Size Calculation (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Calculate required sample size for A/B tests\n",
    "- Understand the relationship between sample size, power, and MDE\n",
    "- Estimate test duration\n",
    "- Make trade-offs between speed and sensitivity\n",
    "\n",
    "### The Business Problem\n",
    "Before launching a test, you need to know: \"How long will this take?\" Running tests too short leads to false conclusions. Running them too long wastes time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Sample Size Factors\n",
    "\n",
    "Sample size depends on four factors:\n",
    "1. **Baseline conversion rate (p‚ÇÅ)**: Current performance\n",
    "2. **Minimum detectable effect (MDE)**: Smallest lift you care about\n",
    "3. **Significance level (Œ±)**: Usually 0.05 (5% false positive risk)\n",
    "4. **Statistical power (1-Œ≤)**: Usually 0.80 (80% chance to detect real effect)\n",
    "\n",
    "**Trade-offs:**\n",
    "- Smaller MDE ‚Üí Larger sample needed\n",
    "- Higher power ‚Üí Larger sample needed\n",
    "- Lower Œ± ‚Üí Larger sample needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "\n",
    "def calculate_sample_size(baseline_rate, minimum_detectable_effect, alpha=0.05, power=0.80):\n",
    "    \"\"\"\n",
    "    Calculate required sample size per group for A/B test.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_rate: Current conversion rate (e.g., 0.05 for 5%)\n",
    "    - minimum_detectable_effect: Relative lift to detect (e.g., 0.10 for 10%)\n",
    "    - alpha: Significance level (default 0.05)\n",
    "    - power: Statistical power (default 0.80)\n",
    "    \n",
    "    Returns:\n",
    "    - Required sample size per group\n",
    "    \"\"\"\n",
    "    # Calculate treatment rate\n",
    "    treatment_rate = baseline_rate * (1 + minimum_detectable_effect)\n",
    "    \n",
    "    # Calculate effect size (Cohen's h)\n",
    "    effect_size = proportion_effectsize(baseline_rate, treatment_rate)\n",
    "    \n",
    "    # Calculate sample size per group\n",
    "    sample_size = zt_ind_solve_power(\n",
    "        effect_size=effect_size,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        ratio=1.0,  # Equal group sizes\n",
    "        alternative='two-sided'\n",
    "    )\n",
    "    \n",
    "    return int(np.ceil(sample_size))\n",
    "\n",
    "# Example: Landing page test\n",
    "baseline_cvr = 0.05  # 5% conversion rate\n",
    "mde = 0.10  # Want to detect 10% relative lift\n",
    "\n",
    "required_sample = calculate_sample_size(baseline_cvr, mde)\n",
    "print(f\"Required sample size per group: {required_sample:,}\")\n",
    "print(f\"Total sample size (both groups): {required_sample * 2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Try It: Calculate Test Duration\n",
    "\n",
    "Given your daily traffic, estimate how long the test needs to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Given:\n",
    "# - Required sample per group: from calculation above\n",
    "# - Daily visitors: 5,000\n",
    "# - Traffic allocation: 50% to each group\n",
    "#\n",
    "# Calculate:\n",
    "# 1. Daily sample per group\n",
    "# 2. Days needed to reach required sample\n",
    "# 3. Should you run for full weeks to account for day-of-week effects?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: MDE Trade-offs\n",
    "\n",
    "Smaller MDE = more sensitivity = longer tests. You need to balance business needs with statistical requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sample sizes for different MDEs\n",
    "baseline = 0.05\n",
    "mde_values = [0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "\n",
    "sample_sizes = []\n",
    "for mde in mde_values:\n",
    "    n = calculate_sample_size(baseline, mde)\n",
    "    sample_sizes.append(n)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([m*100 for m in mde_values], sample_sizes, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Minimum Detectable Effect (%)', fontsize=12)\n",
    "plt.ylabel('Required Sample Size Per Group', fontsize=12)\n",
    "plt.title('Sample Size vs. Minimum Detectable Effect\\n(Baseline CVR: 5%, Power: 80%, Œ±: 0.05)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Add annotations\n",
    "for mde, n in zip(mde_values, sample_sizes):\n",
    "    plt.annotate(f'{n:,}', xy=(mde*100, n), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSample Size Comparison:\")\n",
    "for mde, n in zip(mde_values, sample_sizes):\n",
    "    print(f\"MDE: {mde*100:5.1f}% ‚Üí Sample size: {n:6,} per group ({n*2:7,} total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 2: Multi-Scenario Planning\n",
    "\n",
    "Create a sample size calculator for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scenarios\n",
    "scenarios = pd.DataFrame({\n",
    "    'test_name': ['Email Open Rate', 'Landing Page CVR', 'Add-to-Cart Rate', 'Purchase CVR'],\n",
    "    'baseline_rate': [0.25, 0.05, 0.15, 0.03],\n",
    "    'target_mde': [0.10, 0.15, 0.10, 0.20],\n",
    "    'daily_traffic': [50000, 10000, 8000, 5000]\n",
    "})\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# For each scenario:\n",
    "# 1. Calculate required sample size per group\n",
    "# 2. Calculate total sample size\n",
    "# 3. Estimate test duration in days (50/50 split)\n",
    "# 4. Round up to full weeks\n",
    "# 5. Create a summary table\n",
    "# 6. Which test will take longest? Which is fastest?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Day 51 Mini-Project: Sample Size Calculator Tool\n",
    "\n",
    "Build an interactive sample size calculator with multiple what-if scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a comprehensive function that:\n",
    "# \n",
    "# Takes inputs:\n",
    "# - baseline_rate\n",
    "# - mde\n",
    "# - alpha (default 0.05)\n",
    "# - power (default 0.80)\n",
    "# - daily_traffic\n",
    "# - traffic_allocation (default 0.50)\n",
    "#\n",
    "# Returns a detailed report including:\n",
    "# - Required sample per group\n",
    "# - Total required sample\n",
    "# - Estimated days to complete\n",
    "# - Recommended duration (rounded to full weeks)\n",
    "# - Expected absolute lift (conversions per day)\n",
    "# - Sensitivity analysis (what if MDE is 20% higher/lower?)\n",
    "#\n",
    "# Test it with:\n",
    "# - Baseline: 4%\n",
    "# - MDE: 12.5%\n",
    "# - Daily traffic: 8,000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Day 51 Key Takeaways\n",
    "\n",
    "‚úÖ Sample size calculations prevent underpowered tests  \n",
    "‚úÖ Smaller MDEs require larger samples (longer tests)  \n",
    "‚úÖ Always calculate duration before starting  \n",
    "‚úÖ Business value should inform MDE selection  \n",
    "‚úÖ Account for weekly seasonality in test planning  \n",
    "\n",
    "**Next:** Tomorrow we'll perform two-proportion z-tests!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Day 52: Two-Proportion Z-Tests (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Perform two-proportion z-tests\n",
    "- Calculate confidence intervals\n",
    "- Interpret test statistics and p-values\n",
    "- Make statistical decisions\n",
    "\n",
    "### The Business Problem\n",
    "Your A/B test has collected enough data. Now you need to analyze it properly and determine if the treatment truly outperforms the control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Two-Proportion Z-Test\n",
    "\n",
    "Tests whether two proportions (conversion rates) are significantly different.\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "z = (p‚ÇÅ - p‚ÇÇ) / SE\n",
    "\n",
    "where SE = sqrt(p_pooled * (1 - p_pooled) * (1/n‚ÇÅ + 1/n‚ÇÇ))\n",
    "p_pooled = (x‚ÇÅ + x‚ÇÇ) / (n‚ÇÅ + n‚ÇÇ)\n",
    "```\n",
    "\n",
    "**Decision Rule:**\n",
    "- If |z| > 1.96 (for Œ±=0.05), reject null hypothesis\n",
    "- Or equivalently, if p-value < 0.05, reject null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "def analyze_ab_test(control_conversions, control_visitors, \n",
    "                    treatment_conversions, treatment_visitors,\n",
    "                    alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform two-proportion z-test for A/B test.\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with test results and interpretation\n",
    "    \"\"\"\n",
    "    # Conversion rates\n",
    "    control_rate = control_conversions / control_visitors\n",
    "    treatment_rate = treatment_conversions / treatment_visitors\n",
    "    \n",
    "    # Absolute and relative lift\n",
    "    absolute_lift = treatment_rate - control_rate\n",
    "    relative_lift = (treatment_rate - control_rate) / control_rate\n",
    "    \n",
    "    # Perform z-test\n",
    "    count = np.array([treatment_conversions, control_conversions])\n",
    "    nobs = np.array([treatment_visitors, control_visitors])\n",
    "    z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
    "    \n",
    "    # Confidence interval for difference\n",
    "    se_diff = np.sqrt(\n",
    "        (control_rate * (1 - control_rate) / control_visitors) +\n",
    "        (treatment_rate * (1 - treatment_rate) / treatment_visitors)\n",
    "    )\n",
    "    ci_lower = absolute_lift - 1.96 * se_diff\n",
    "    ci_upper = absolute_lift + 1.96 * se_diff\n",
    "    \n",
    "    # Decision\n",
    "    is_significant = p_value < alpha\n",
    "    \n",
    "    results = {\n",
    "        'control_rate': control_rate,\n",
    "        'treatment_rate': treatment_rate,\n",
    "        'absolute_lift': absolute_lift,\n",
    "        'relative_lift': relative_lift,\n",
    "        'z_statistic': z_stat,\n",
    "        'p_value': p_value,\n",
    "        'ci_95_lower': ci_lower,\n",
    "        'ci_95_upper': ci_upper,\n",
    "        'is_significant': is_significant,\n",
    "        'decision': 'SIGNIFICANT' if is_significant else 'NOT SIGNIFICANT'\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Landing page test\n",
    "results = analyze_ab_test(\n",
    "    control_conversions=350,\n",
    "    control_visitors=10000,\n",
    "    treatment_conversions=412,\n",
    "    treatment_visitors=10000\n",
    ")\n",
    "\n",
    "print(\"A/B Test Results\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Control CVR:     {results['control_rate']:.4f} ({results['control_rate']*100:.2f}%)\")\n",
    "print(f\"Treatment CVR:   {results['treatment_rate']:.4f} ({results['treatment_rate']*100:.2f}%)\")\n",
    "print(f\"Absolute Lift:   {results['absolute_lift']:.4f} ({results['absolute_lift']*100:.2f} percentage points)\")\n",
    "print(f\"Relative Lift:   {results['relative_lift']:.4f} ({results['relative_lift']*100:.2f}%)\")\n",
    "print(f\"\\nZ-statistic:     {results['z_statistic']:.4f}\")\n",
    "print(f\"P-value:         {results['p_value']:.4f}\")\n",
    "print(f\"95% CI:          [{results['ci_95_lower']:.4f}, {results['ci_95_upper']:.4f}]\")\n",
    "print(f\"\\nDecision:        {results['decision']}\")\n",
    "\n",
    "if results['is_significant']:\n",
    "    print(\"\\n‚úÖ RECOMMENDATION: Implement the treatment variant.\")\n",
    "    print(f\"   Expected lift: {results['relative_lift']*100:.1f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  RECOMMENDATION: Insufficient evidence. Don't implement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Try It: Analyze Real Test Data\n",
    "\n",
    "Analyze multiple tests and make recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Analyze these three tests:\n",
    "#\n",
    "# Test 1: Email subject line\n",
    "# Control: 1,250 opens / 50,000 sends\n",
    "# Treatment: 1,450 opens / 50,000 sends\n",
    "#\n",
    "# Test 2: CTA button color\n",
    "# Control: 180 clicks / 8,000 visitors\n",
    "# Treatment: 195 clicks / 8,000 visitors\n",
    "#\n",
    "# Test 3: Pricing page layout\n",
    "# Control: 420 purchases / 5,000 visitors\n",
    "# Treatment: 485 purchases / 5,000 visitors\n",
    "#\n",
    "# For each: Calculate results and make recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Confidence Intervals\n",
    "\n",
    "Confidence intervals provide a range of plausible values for the true lift. If the CI includes zero, the result is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confidence intervals for multiple tests\n",
    "test_results = [\n",
    "    ('Email A', 0.015, 0.005, 0.025),\n",
    "    ('Landing Page B', 0.032, 0.018, 0.046),\n",
    "    ('Ad Creative C', 0.008, -0.002, 0.018),\n",
    "    ('Checkout Flow D', -0.005, -0.015, 0.005),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, (name, lift, ci_low, ci_high) in enumerate(test_results):\n",
    "    color = 'green' if ci_low > 0 else ('red' if ci_high < 0 else 'gray')\n",
    "    ax.plot([ci_low, ci_high], [i, i], 'o-', linewidth=3, markersize=8, color=color)\n",
    "    ax.plot([lift], [i], 'D', markersize=10, color=color)\n",
    "\n",
    "ax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.set_yticks(range(len(test_results)))\n",
    "ax.set_yticklabels([name for name, *_ in test_results])\n",
    "ax.set_xlabel('Absolute Lift (percentage points)', fontsize=12)\n",
    "ax.set_title('95% Confidence Intervals for Test Results\\n(Green = Significant Win, Red = Significant Loss, Gray = Inconclusive)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 3: One-Sided vs Two-Sided Tests\n",
    "\n",
    "Understand when to use one-sided vs two-sided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "control_conv = 400\n",
    "control_vis = 10000\n",
    "treatment_conv = 445\n",
    "treatment_vis = 10000\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1. Perform a two-sided test (can treatment be better OR worse?)\n",
    "# 2. Perform a one-sided test (can treatment be better?)\n",
    "# 3. Compare the p-values\n",
    "# 4. When would you use one-sided? When two-sided?\n",
    "# 5. What are the risks of using one-sided tests?\n",
    "#\n",
    "# Hint: Use proportions_ztest with alternative='larger' for one-sided\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Day 52 Mini-Project: Automated Test Analyzer\n",
    "\n",
    "Build a comprehensive A/B test analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a function that takes test data and produces:\n",
    "#\n",
    "# 1. Statistical results (z-stat, p-value, CIs)\n",
    "# 2. Business metrics (absolute lift, relative lift, incremental conversions)\n",
    "# 3. Visual report:\n",
    "#    - Conversion rate comparison (bar chart)\n",
    "#    - Confidence interval visualization\n",
    "# 4. Written recommendation with reasoning\n",
    "# 5. Revenue impact calculation (if revenue per conversion is provided)\n",
    "#\n",
    "# Test it with this data:\n",
    "# Control: 3,250 conversions from 100,000 visitors\n",
    "# Treatment: 3,680 conversions from 100,000 visitors\n",
    "# Revenue per conversion: $45\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Day 52 Key Takeaways\n",
    "\n",
    "‚úÖ Two-proportion z-tests are the workhorse of A/B testing  \n",
    "‚úÖ P-values quantify evidence against the null hypothesis  \n",
    "‚úÖ Confidence intervals show the range of plausible effects  \n",
    "‚úÖ Statistical significance ‚â† practical significance  \n",
    "‚úÖ Always report both relative and absolute lift  \n",
    "\n",
    "**Next:** Tomorrow we'll explore statistical vs practical significance!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Day 53: Statistical vs Practical Significance (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Distinguish statistical from practical significance\n",
    "- Calculate business impact of test results\n",
    "- Make economically rational decisions\n",
    "- Avoid the \"significance trap\"\n",
    "\n",
    "### The Business Problem\n",
    "You found a statistically significant 1% lift in conversion rate. Should you implement it? What if it requires 3 months of engineering work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Statistical ‚â† Practical Significance\n",
    "\n",
    "**Statistical Significance:** The effect is unlikely due to chance (p < 0.05)\n",
    "\n",
    "**Practical Significance:** The effect is large enough to matter for business decisions\n",
    "\n",
    "With large samples, tiny effects become statistically significant but may not be worth implementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Large sample, small effect\n",
    "control_conv = 10000\n",
    "control_vis = 200000  # 5.00% CVR\n",
    "treatment_conv = 10200\n",
    "treatment_vis = 200000  # 5.10% CVR (2% relative lift)\n",
    "\n",
    "results = analyze_ab_test(control_conv, control_vis, treatment_conv, treatment_vis)\n",
    "\n",
    "print(\"Large Sample, Small Effect\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size per group: {control_vis:,}\")\n",
    "print(f\"Relative lift: {results['relative_lift']*100:.2f}%\")\n",
    "print(f\"P-value: {results['p_value']:.4f}\")\n",
    "print(f\"Statistical significance: {results['decision']}\")\n",
    "print(f\"\\nBut is a {results['relative_lift']*100:.1f}% lift worth implementing?\")\n",
    "print(f\"That depends on:\")\n",
    "print(f\"  - Implementation cost\")\n",
    "print(f\"  - Maintenance burden\")\n",
    "print(f\"  - Opportunity cost\")\n",
    "print(f\"  - Revenue impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Try It: Calculate Business Impact\n",
    "\n",
    "Determine if statistically significant results are worth implementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Given:\n",
    "# - Current monthly visitors: 500,000\n",
    "# - Current CVR: 5.0%\n",
    "# - Treatment CVR: 5.1% (2% relative lift)\n",
    "# - Revenue per conversion: $50\n",
    "# - Implementation cost: $25,000\n",
    "# - Monthly maintenance: $2,000\n",
    "#\n",
    "# Calculate:\n",
    "# 1. Monthly incremental conversions\n",
    "# 2. Monthly incremental revenue\n",
    "# 3. Annual incremental revenue\n",
    "# 4. Payback period for implementation cost\n",
    "# 5. ROI after 1 year\n",
    "# 6. Should you implement? Why or why not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ Concept: Minimum Practical Difference\n",
    "\n",
    "Before testing, define the **minimum practical difference (MPD)**: the smallest effect worth implementing.\n",
    "\n",
    "This is different from MDE (minimum detectable effect):\n",
    "- **MDE**: What you can reliably detect\n",
    "- **MPD**: What's worth implementing\n",
    "\n",
    "Ideally, MDE ‚â§ MPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mpd(monthly_volume, baseline_cvr, revenue_per_conversion, \n",
    "                  implementation_cost, desired_payback_months=6):\n",
    "    \"\"\"\n",
    "    Calculate minimum practical difference based on economic criteria.\n",
    "    \n",
    "    Returns:\n",
    "    - Minimum relative lift needed to justify implementation\n",
    "    \"\"\"\n",
    "    # Current monthly conversions\n",
    "    baseline_conversions = monthly_volume * baseline_cvr\n",
    "    \n",
    "    # Incremental conversions needed to payback in desired timeframe\n",
    "    required_incremental_revenue = implementation_cost / desired_payback_months\n",
    "    required_incremental_conversions = required_incremental_revenue / revenue_per_conversion\n",
    "    \n",
    "    # Required lift\n",
    "    required_relative_lift = required_incremental_conversions / baseline_conversions\n",
    "    \n",
    "    return required_relative_lift\n",
    "\n",
    "# Example\n",
    "mpd = calculate_mpd(\n",
    "    monthly_volume=500000,\n",
    "    baseline_cvr=0.05,\n",
    "    revenue_per_conversion=50,\n",
    "    implementation_cost=25000,\n",
    "    desired_payback_months=6\n",
    ")\n",
    "\n",
    "print(f\"Minimum Practical Difference: {mpd*100:.2f}%\")\n",
    "print(f\"\\nAny lift below {mpd*100:.2f}% won't pay back within 6 months.\")\n",
    "print(f\"Even if statistically significant, it's not worth implementing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úèÔ∏è Exercise 4: Economic Decision Framework\n",
    "\n",
    "Build a decision framework that considers both statistical and practical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scenarios = pd.DataFrame({\n",
    "    'test': ['A', 'B', 'C', 'D'],\n",
    "    'relative_lift': [0.15, 0.03, 0.08, 0.25],\n",
    "    'p_value': [0.001, 0.032, 0.156, 0.089],\n",
    "    'implementation_cost': [50000, 5000, 30000, 100000],\n",
    "    'monthly_visitors': [1000000, 500000, 200000, 2000000],\n",
    "    'baseline_cvr': [0.04, 0.06, 0.03, 0.05],\n",
    "    'revenue_per_conversion': [75, 45, 120, 60]\n",
    "})\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# For each test:\n",
    "# 1. Determine statistical significance (p < 0.05)\n",
    "# 2. Calculate annual incremental revenue\n",
    "# 3. Calculate ROI (annual_revenue / implementation_cost)\n",
    "# 4. Calculate payback period in months\n",
    "# 5. Make a recommendation:\n",
    "#    - \"Implement\" if statistically significant AND ROI > 200%\n",
    "#    - \"Don't implement\" if not statistically significant\n",
    "#    - \"Consider\" if significant but ROI 100-200%\n",
    "#    - \"Don't implement\" if ROI < 100%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Day 53 Mini-Project: Test Prioritization Framework\n",
    "\n",
    "Create a framework to prioritize which tests to run based on potential business impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# You have 5 test ideas. Prioritize them based on:\n",
    "# - Expected lift\n",
    "# - Affected traffic volume\n",
    "# - Implementation complexity (cost)\n",
    "# - Time to implement\n",
    "# - Confidence in success (probability)\n",
    "#\n",
    "# Create a scoring system that considers:\n",
    "# 1. Expected value = (probability_of_success √ó expected_lift √ó volume √ó value_per_conversion)\n",
    "# 2. Implementation cost\n",
    "# 3. Time to results\n",
    "#\n",
    "# Calculate a priority score and rank the tests.\n",
    "#\n",
    "# Test ideas:\n",
    "test_ideas = pd.DataFrame({\n",
    "    'test': ['New homepage hero', 'Simplified checkout', 'Product page redesign', \n",
    "             'Email frequency', 'Mobile app onboarding'],\n",
    "    'expected_lift': [0.10, 0.20, 0.15, 0.08, 0.25],\n",
    "    'probability_of_success': [0.60, 0.40, 0.50, 0.70, 0.30],\n",
    "    'monthly_affected_users': [500000, 100000, 300000, 200000, 50000],\n",
    "    'baseline_cvr': [0.05, 0.30, 0.08, 0.12, 0.20],\n",
    "    'revenue_per_conversion': [60, 80, 75, 50, 100],\n",
    "    'implementation_weeks': [6, 12, 8, 2, 10],\n",
    "    'implementation_cost': [40000, 100000, 60000, 10000, 80000]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Day 53 Key Takeaways\n",
    "\n",
    "‚úÖ Statistical significance doesn't guarantee business value  \n",
    "‚úÖ Always calculate ROI before implementing  \n",
    "‚úÖ Define minimum practical difference upfront  \n",
    "‚úÖ Consider implementation costs and payback period  \n",
    "‚úÖ Large samples can make tiny effects \"significant\"  \n",
    "\n",
    "**Next:** Tomorrow we'll tackle the multiple testing problem!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Day 54-56: Advanced Topics (Condensed)\n",
    "\n",
    "### Day 54: Multiple Testing Problem\n",
    "- Bonferroni correction\n",
    "- False discovery rate (FDR)\n",
    "- When and how to correct for multiple comparisons\n",
    "\n",
    "### Day 55: Sequential Testing\n",
    "- Always-valid p-values\n",
    "- Sequential probability ratio test (SPRT)\n",
    "- Stopping rules\n",
    "\n",
    "### Day 56: Capstone - Design and Analyze A/B Test\n",
    "- Full end-to-end test design\n",
    "- Sample size calculation\n",
    "- Analysis and recommendation\n",
    "- Business case presentation\n",
    "\n",
    "*Note: These sections would be fully expanded in a production version with detailed code examples, exercises, and mini-projects.*\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Week 8 Complete!\n",
    "\n",
    "**Congratulations!** You've mastered A/B testing fundamentals.\n",
    "\n",
    "**What You've Learned:**\n",
    "- ‚úÖ A/B test design and hypothesis formulation\n",
    "- ‚úÖ Sample size calculations and power analysis\n",
    "- ‚úÖ Two-proportion z-tests and statistical inference\n",
    "- ‚úÖ Business-focused decision making\n",
    "- ‚úÖ Multiple testing and sequential testing\n",
    "\n",
    "**Next Week:** Attribution modeling - understanding the customer journey!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
