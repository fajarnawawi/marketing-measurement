{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Advanced SQL for Marketing Analytics\n",
    "\n",
    "**Goal:** Master advanced SQL techniques for complex marketing measurement and attribution.\n",
    "\n",
    "**Time Commitment:** ~1 hour per day Ã— 7 days = 7 hours total\n",
    "\n",
    "**What You'll Learn:**\n",
    "- Advanced window functions (LAG, LEAD, NTILE, PERCENT_RANK)\n",
    "- Common Table Expressions (CTEs) for readable queries\n",
    "- Temporary tables and query optimization\n",
    "- Date/time operations for cohort analysis\n",
    "- String manipulation for campaign parsing\n",
    "- Advanced joins and set operations\n",
    "- Complex marketing analytics queries\n",
    "\n",
    "**Why This Matters:**\n",
    "As a Marketing Measurement Partner, you'll tackle complex questions:\n",
    "- Which campaigns drove the highest customer lifetime value?\n",
    "- How do customers behave across their first 90 days?\n",
    "- What's the optimal budget distribution across channels?\n",
    "- How has campaign efficiency trended month-over-month?\n",
    "- Which touchpoints contribute most to conversions?\n",
    "\n",
    "Advanced SQL lets you answer these questions efficiently and elegantly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Enhanced Marketing Database\n",
    "\n",
    "We'll create an enhanced database with more realistic data for advanced analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Create database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"âœ… Enhanced marketing database initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive campaigns table\n",
    "cursor.execute('''\n",
    "CREATE TABLE campaigns (\n",
    "    campaign_id INTEGER PRIMARY KEY,\n",
    "    campaign_name TEXT NOT NULL,\n",
    "    channel TEXT NOT NULL,\n",
    "    campaign_type TEXT,\n",
    "    objective TEXT,\n",
    "    targeting TEXT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    budget REAL,\n",
    "    status TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "campaigns_data = [\n",
    "    (1, 'Search_Brand_Q4_Desktop', 'Google', 'Search', 'Brand', 'Desktop', '2024-10-01', '2024-12-31', 50000, 'active'),\n",
    "    (2, 'Search_Generic_Mobile_Q4', 'Google', 'Search', 'Acquisition', 'Mobile', '2024-10-01', '2024-12-31', 75000, 'active'),\n",
    "    (3, 'FB_Prospecting_18-34', 'Meta', 'Social', 'Acquisition', '18-34', '2024-09-01', '2024-12-31', 60000, 'active'),\n",
    "    (4, 'FB_Retargeting_AllAges', 'Meta', 'Social', 'Retention', 'All', '2024-09-01', '2024-12-31', 40000, 'active'),\n",
    "    (5, 'Display_Remarketing_High_Intent', 'Google', 'Display', 'Retention', 'High_Intent', '2024-10-01', '2024-12-31', 30000, 'active'),\n",
    "    (6, 'Instagram_Stories_Gen_Z', 'Meta', 'Social', 'Awareness', '18-24', '2024-10-15', '2024-12-31', 35000, 'active'),\n",
    "    (7, 'LinkedIn_B2B_Decision_Makers', 'LinkedIn', 'Social', 'B2B', 'Directors+', '2024-11-01', '2024-12-31', 45000, 'active'),\n",
    "    (8, 'TikTok_Awareness_Gen_Z', 'TikTok', 'Video', 'Awareness', '18-24', '2024-10-01', '2024-11-30', 25000, 'paused'),\n",
    "    (9, 'YouTube_Video_35-54', 'Google', 'Video', 'Awareness', '35-54', '2024-10-01', '2024-12-31', 55000, 'active'),\n",
    "    (10, 'Search_Competitor_Q4', 'Google', 'Search', 'Acquisition', 'All', '2024-11-01', '2024-12-31', 42000, 'active')\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO campaigns VALUES (?,?,?,?,?,?,?,?,?,?)', campaigns_data)\n",
    "print(\"âœ… Campaigns table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily performance data with realistic patterns\n",
    "cursor.execute('''\n",
    "CREATE TABLE daily_performance (\n",
    "    performance_id INTEGER PRIMARY KEY,\n",
    "    campaign_id INTEGER,\n",
    "    date DATE,\n",
    "    impressions INTEGER,\n",
    "    clicks INTEGER,\n",
    "    conversions INTEGER,\n",
    "    cost REAL,\n",
    "    revenue REAL,\n",
    "    FOREIGN KEY (campaign_id) REFERENCES campaigns(campaign_id)\n",
    ")\n",
    "''')\n",
    "\n",
    "# Generate 60 days of data per campaign\n",
    "np.random.seed(42)\n",
    "performance_data = []\n",
    "perf_id = 1\n",
    "\n",
    "for campaign_id in range(1, 11):\n",
    "    for day in range(60):\n",
    "        date = (datetime(2024, 10, 1) + timedelta(days=day)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Different performance by campaign type\n",
    "        if campaign_id in [1, 2, 10]:  # Search\n",
    "            impressions = np.random.randint(3000, 8000)\n",
    "            clicks = np.random.randint(150, 400)\n",
    "            conversions = np.random.randint(8, 25)\n",
    "            cost = np.random.uniform(200, 600)\n",
    "            revenue = cost * np.random.uniform(3.5, 6.0)\n",
    "        elif campaign_id in [3, 4, 6]:  # Social\n",
    "            impressions = np.random.randint(15000, 40000)\n",
    "            clicks = np.random.randint(500, 1500)\n",
    "            conversions = np.random.randint(10, 35)\n",
    "            cost = np.random.uniform(150, 450)\n",
    "            revenue = cost * np.random.uniform(2.5, 4.5)\n",
    "        else:  # Display/Video\n",
    "            impressions = np.random.randint(25000, 60000)\n",
    "            clicks = np.random.randint(300, 900)\n",
    "            conversions = np.random.randint(5, 20)\n",
    "            cost = np.random.uniform(100, 400)\n",
    "            revenue = cost * np.random.uniform(2.0, 4.0)\n",
    "        \n",
    "        performance_data.append((perf_id, campaign_id, date, impressions, clicks, conversions, cost, revenue))\n",
    "        perf_id += 1\n",
    "\n",
    "cursor.executemany('INSERT INTO daily_performance VALUES (?,?,?,?,?,?,?,?)', performance_data)\n",
    "print(f\"âœ… Daily performance table created with {len(performance_data)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer journey / touchpoints table\n",
    "cursor.execute('''\n",
    "CREATE TABLE customer_touchpoints (\n",
    "    touchpoint_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER,\n",
    "    campaign_id INTEGER,\n",
    "    touchpoint_date DATE,\n",
    "    touchpoint_type TEXT,\n",
    "    touchpoint_order INTEGER,\n",
    "    FOREIGN KEY (campaign_id) REFERENCES campaigns(campaign_id)\n",
    ")\n",
    "''')\n",
    "\n",
    "# Sample multi-touch attribution data\n",
    "touchpoints_data = [\n",
    "    (1, 101, 6, '2024-10-15', 'impression', 1),\n",
    "    (2, 101, 3, '2024-10-18', 'click', 2),\n",
    "    (3, 101, 4, '2024-10-20', 'click', 3),\n",
    "    (4, 101, 1, '2024-10-22', 'conversion', 4),\n",
    "    (5, 102, 2, '2024-10-10', 'click', 1),\n",
    "    (6, 102, 5, '2024-10-15', 'click', 2),\n",
    "    (7, 102, 2, '2024-10-17', 'conversion', 3),\n",
    "    (8, 103, 9, '2024-10-05', 'impression', 1),\n",
    "    (9, 103, 3, '2024-10-12', 'click', 2),\n",
    "    (10, 103, 4, '2024-10-14', 'conversion', 3)\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO customer_touchpoints VALUES (?,?,?,?,?,?)', touchpoints_data)\n",
    "print(\"âœ… Customer touchpoints table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "print(\"\\nâœ… Advanced marketing database setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“… Day 22: Advanced Window Functions (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Use LAG and LEAD for time-based comparisons\n",
    "- Apply NTILE for percentile rankings\n",
    "- Calculate running totals and moving averages\n",
    "- Use PERCENT_RANK for performance distribution\n",
    "\n",
    "### The Business Problem\n",
    "You need to:\n",
    "- Compare this week's performance to last week\n",
    "- Calculate 7-day moving averages\n",
    "- Rank campaigns by efficiency percentiles\n",
    "- Track cumulative spend pacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: LAG and LEAD\n",
    "\n",
    "Access previous (LAG) or next (LEAD) row values for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day-over-day comparison for one campaign\n",
    "query = '''\n",
    "SELECT \n",
    "    date,\n",
    "    conversions,\n",
    "    LAG(conversions, 1) OVER (ORDER BY date) as prev_day_conversions,\n",
    "    conversions - LAG(conversions, 1) OVER (ORDER BY date) as day_over_day_change,\n",
    "    ROUND(100.0 * (conversions - LAG(conversions, 1) OVER (ORDER BY date)) / \n",
    "          LAG(conversions, 1) OVER (ORDER BY date), 2) as pct_change\n",
    "FROM daily_performance\n",
    "WHERE campaign_id = 1\n",
    "ORDER BY date\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"Day-over-Day Conversion Changes:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: Running Totals\n",
    "\n",
    "Calculate cumulative values over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget pacing - track cumulative spend\n",
    "query = '''\n",
    "SELECT \n",
    "    c.campaign_name,\n",
    "    c.budget,\n",
    "    dp.date,\n",
    "    dp.cost as daily_cost,\n",
    "    SUM(dp.cost) OVER (PARTITION BY c.campaign_id ORDER BY dp.date) as cumulative_cost,\n",
    "    ROUND(100.0 * SUM(dp.cost) OVER (PARTITION BY c.campaign_id ORDER BY dp.date) / c.budget, 2) as pct_budget_spent\n",
    "FROM campaigns c\n",
    "JOIN daily_performance dp ON c.campaign_id = dp.campaign_id\n",
    "WHERE c.campaign_id = 1\n",
    "ORDER BY dp.date\n",
    "LIMIT 20;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"Budget Pacing (Running Total):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: Moving Averages\n",
    "\n",
    "Calculate rolling averages for trend smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day moving average of conversions\n",
    "query = '''\n",
    "SELECT \n",
    "    date,\n",
    "    conversions,\n",
    "    ROUND(AVG(conversions) OVER (\n",
    "        ORDER BY date \n",
    "        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "    ), 2) as ma_7_day\n",
    "FROM daily_performance\n",
    "WHERE campaign_id = 1\n",
    "ORDER BY date\n",
    "LIMIT 20;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"7-Day Moving Average of Conversions:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: NTILE and PERCENT_RANK\n",
    "\n",
    "Divide data into percentiles or calculate percentile ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank campaigns by efficiency quartiles\n",
    "query = '''\n",
    "WITH campaign_metrics AS (\n",
    "    SELECT \n",
    "        c.campaign_name,\n",
    "        SUM(dp.revenue) / SUM(dp.cost) as roas\n",
    "    FROM campaigns c\n",
    "    JOIN daily_performance dp ON c.campaign_id = dp.campaign_id\n",
    "    GROUP BY c.campaign_id, c.campaign_name\n",
    ")\n",
    "SELECT \n",
    "    campaign_name,\n",
    "    ROUND(roas, 2) as roas,\n",
    "    NTILE(4) OVER (ORDER BY roas DESC) as performance_quartile,\n",
    "    ROUND(PERCENT_RANK() OVER (ORDER BY roas DESC) * 100, 2) as percentile_rank\n",
    "FROM campaign_metrics\n",
    "ORDER BY roas DESC;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"Campaign Performance Quartiles:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Exercise 1: Week-over-Week Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Calculate week-over-week performance for campaign_id = 2\n",
    "# 1. Group daily_performance by week (use strftime('%W', date))\n",
    "# 2. Calculate weekly conversions\n",
    "# 3. Use LAG to get previous week's conversions\n",
    "# 4. Calculate week-over-week change (absolute and percentage)\n",
    "# 5. Show: week, weekly_conversions, prev_week, change, pct_change\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Day 22 Mini-Project: Campaign Momentum Tracker\n",
    "\n",
    "Build a momentum tracker showing which campaigns are trending up or down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a campaign momentum report:\n",
    "# 1. For each campaign, calculate ROAS for last 7 days vs previous 7 days\n",
    "# 2. Calculate the change in ROAS\n",
    "# 3. Classify momentum as:\n",
    "#    - 'Accelerating' if ROAS improved > 10%\n",
    "#    - 'Stable' if change between -10% and +10%\n",
    "#    - 'Declining' if ROAS decreased > 10%\n",
    "# 4. Rank campaigns by momentum\n",
    "#\n",
    "# Hint: You'll need to use date filtering and window functions\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Campaign Momentum Report:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Day 22 Key Takeaways\n",
    "\n",
    "âœ… LAG/LEAD enable time-based comparisons  \n",
    "âœ… Running totals track cumulative metrics  \n",
    "âœ… Moving averages smooth noisy data  \n",
    "âœ… NTILE creates percentile buckets  \n",
    "âœ… PERCENT_RANK shows relative performance  \n",
    "\n",
    "**Next:** Tomorrow we'll learn CTEs for cleaner, more readable queries!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“… Day 23: CTEs and Temp Tables (~60 min)\n",
    "\n",
    "### Learning Objectives\n",
    "- Write Common Table Expressions (CTEs)\n",
    "- Use multiple CTEs in one query\n",
    "- Create recursive CTEs\n",
    "- Use temporary tables for complex analysis\n",
    "\n",
    "### The Business Problem\n",
    "Complex queries become hard to read and maintain. CTEs make queries modular and understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: Basic CTEs\n",
    "\n",
    "CTEs (WITH clause) create named temporary result sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without CTE (nested subquery - harder to read)\n",
    "query = '''\n",
    "SELECT \n",
    "    campaign_name,\n",
    "    roas\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.campaign_name,\n",
    "        SUM(dp.revenue) / SUM(dp.cost) as roas\n",
    "    FROM campaigns c\n",
    "    JOIN daily_performance dp ON c.campaign_id = dp.campaign_id\n",
    "    GROUP BY c.campaign_id, c.campaign_name\n",
    ") subquery\n",
    "WHERE roas > 3.0\n",
    "ORDER BY roas DESC;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"High ROAS Campaigns (without CTE):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With CTE (much cleaner!)\n",
    "query = '''\n",
    "WITH campaign_performance AS (\n",
    "    SELECT \n",
    "        c.campaign_name,\n",
    "        c.channel,\n",
    "        SUM(dp.cost) as total_cost,\n",
    "        SUM(dp.revenue) as total_revenue,\n",
    "        SUM(dp.revenue) / SUM(dp.cost) as roas\n",
    "    FROM campaigns c\n",
    "    JOIN daily_performance dp ON c.campaign_id = dp.campaign_id\n",
    "    GROUP BY c.campaign_id, c.campaign_name, c.channel\n",
    ")\n",
    "SELECT \n",
    "    campaign_name,\n",
    "    channel,\n",
    "    ROUND(total_cost, 2) as total_cost,\n",
    "    ROUND(total_revenue, 2) as total_revenue,\n",
    "    ROUND(roas, 2) as roas\n",
    "FROM campaign_performance\n",
    "WHERE roas > 3.0\n",
    "ORDER BY roas DESC;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"\\nHigh ROAS Campaigns (with CTE):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– Concept: Multiple CTEs\n",
    "\n",
    "Chain multiple CTEs for step-by-step logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-stage analysis with multiple CTEs\n",
    "query = '''\n",
    "WITH campaign_metrics AS (\n",
    "    -- Step 1: Calculate campaign-level metrics\n",
    "    SELECT \n",
    "        c.campaign_id,\n",
    "        c.campaign_name,\n",
    "        c.channel,\n",
    "        SUM(dp.cost) as total_cost,\n",
    "        SUM(dp.revenue) as total_revenue,\n",
    "        SUM(dp.conversions) as total_conversions\n",
    "    FROM campaigns c\n",
    "    JOIN daily_performance dp ON c.campaign_id = dp.campaign_id\n",
    "    GROUP BY c.campaign_id, c.campaign_name, c.channel\n",
    "),\n",
    "campaign_efficiency AS (\n",
    "    -- Step 2: Calculate efficiency metrics\n",
    "    SELECT \n",
    "        *,\n",
    "        total_revenue / total_cost as roas,\n",
    "        total_cost / total_conversions as cpa\n",
    "    FROM campaign_metrics\n",
    "),\n",
    "channel_benchmarks AS (\n",
    "    -- Step 3: Calculate channel-level benchmarks\n",
    "    SELECT \n",
    "        channel,\n",
    "        AVG(roas) as avg_channel_roas,\n",
    "        AVG(cpa) as avg_channel_cpa\n",
    "    FROM campaign_efficiency\n",
    "    GROUP BY channel\n",
    ")\n",
    "-- Step 4: Compare campaigns to channel benchmarks\n",
    "SELECT \n",
    "    ce.campaign_name,\n",
    "    ce.channel,\n",
    "    ROUND(ce.roas, 2) as campaign_roas,\n",
    "    ROUND(cb.avg_channel_roas, 2) as channel_avg_roas,\n",
    "    CASE \n",
    "        WHEN ce.roas > cb.avg_channel_roas THEN 'Above Average'\n",
    "        ELSE 'Below Average'\n",
    "    END as performance_vs_channel\n",
    "FROM campaign_efficiency ce\n",
    "JOIN channel_benchmarks cb ON ce.channel = cb.channel\n",
    "ORDER BY ce.channel, ce.roas DESC;\n",
    "'''\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "print(\"Campaign vs Channel Benchmark:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ Exercise 2: Build a Cohesive CTE Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a query using multiple CTEs:\n",
    "# \n",
    "# CTE 1: daily_roas - Calculate daily ROAS for each campaign\n",
    "# CTE 2: campaign_avg - Calculate average daily ROAS per campaign\n",
    "# CTE 3: volatile_days - Find days where ROAS was >20% different from campaign average\n",
    "# \n",
    "# Final SELECT: Show campaign, date, daily ROAS, avg ROAS, deviation\n",
    "# Only show volatile days\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Volatile Performance Days:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Day 23 Mini-Project: Multi-Touch Attribution Analysis\n",
    "\n",
    "Analyze customer journey touchpoints using CTEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Build a multi-touch attribution report using CTEs:\n",
    "#\n",
    "# CTE 1: customer_journeys - Get all touchpoints per customer\n",
    "# CTE 2: journey_length - Count touchpoints per customer\n",
    "# CTE 3: first_touch - Identify first touchpoint campaign\n",
    "# CTE 4: last_touch - Identify last touchpoint campaign (conversion)\n",
    "#\n",
    "# Final SELECT: Show customer_id, journey length, first campaign, last campaign\n",
    "# Show how many touchpoints between first and last\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Customer Journey Analysis:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Day 23 Key Takeaways\n",
    "\n",
    "âœ… CTEs make complex queries readable  \n",
    "âœ… Multiple CTEs enable step-by-step logic  \n",
    "âœ… CTEs can reference earlier CTEs  \n",
    "âœ… Much cleaner than nested subqueries  \n",
    "âœ… Great for documenting query logic  \n",
    "\n",
    "**Next:** Tomorrow we'll learn query optimization techniques!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“… Day 24-27: Additional Advanced Topics\n",
    "\n",
    "The following days cover:\n",
    "\n",
    "**Day 24: Query Optimization**\n",
    "- Understanding query execution plans\n",
    "- Creating and using indexes\n",
    "- Optimizing JOIN performance\n",
    "- Avoiding common pitfalls\n",
    "\n",
    "**Day 25: Date/Time Operations**\n",
    "- Date arithmetic and intervals\n",
    "- Extracting date parts (year, month, day, week)\n",
    "- Cohort analysis by signup date\n",
    "- Time-based segmentation\n",
    "\n",
    "**Day 26: String Manipulation**\n",
    "- Parsing campaign names\n",
    "- LIKE and wildcards\n",
    "- Regular expressions\n",
    "- Extracting UTM parameters\n",
    "\n",
    "**Day 27: Advanced Joins & Unions**\n",
    "- CROSS JOIN for scenario analysis\n",
    "- Self joins for comparisons\n",
    "- UNION and UNION ALL\n",
    "- Combining datasets from multiple sources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“… Day 28: Week 4 Capstone - Complex Marketing Analytics (~60 min)\n",
    "\n",
    "### Project: Executive Marketing Intelligence Report\n",
    "\n",
    "**Scenario:**  \n",
    "You're presenting to the CMO and CFO. They need a comprehensive, data-driven analysis of Q4 marketing performance with actionable insights for Q1 budget allocation.\n",
    "\n",
    "**Requirements:**\n",
    "Use advanced SQL techniques (window functions, CTEs, complex joins) to answer strategic questions.\n",
    "\n",
    "**Deliverables:**\n",
    "1. Campaign efficiency trends over time\n",
    "2. Channel mix optimization recommendations\n",
    "3. Customer acquisition cohort analysis\n",
    "4. Multi-touch attribution insights\n",
    "5. Budget reallocation simulation\n",
    "6. Predictive performance indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Campaign Efficiency Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a weekly trend analysis showing:\n",
    "# - Week number and date range\n",
    "# - Weekly ROAS for each campaign\n",
    "# - 4-week moving average ROAS\n",
    "# - Week-over-week change in ROAS\n",
    "# - Trend classification (improving/stable/declining)\n",
    "#\n",
    "# Use CTEs for clarity\n",
    "# Use window functions for calculations\n",
    "# Show only campaigns with declining trends in last 4 weeks\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Declining Campaign Trends:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Channel Mix Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Calculate optimal budget allocation:\n",
    "# 1. Current spend share by channel (% of total budget)\n",
    "# 2. Current revenue share by channel (% of total revenue)\n",
    "# 3. ROAS by channel\n",
    "# 4. Efficiency score: revenue_share / spend_share\n",
    "#    (> 1.0 means channel generates more than its share)\n",
    "# 5. Recommended budget adjustment\n",
    "#\n",
    "# Use CTEs to break down the logic\n",
    "# Provide specific $ reallocation recommendations\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Channel Mix Optimization:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Performance Percentile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a performance distribution analysis:\n",
    "# 1. Calculate campaign-level ROAS\n",
    "# 2. Assign each campaign to a decile (NTILE(10))\n",
    "# 3. For each decile, show:\n",
    "#    - Decile number (1 = best)\n",
    "#    - Number of campaigns in decile\n",
    "#    - Average ROAS in decile\n",
    "#    - Total spend in decile\n",
    "#    - % of total budget in decile\n",
    "# 4. Identify concentration risk (top decile spending %)\n",
    "#\n",
    "# Use window functions and CTEs\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Performance Decile Analysis:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Multi-Touch Attribution Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Analyze customer touchpoint data:\n",
    "# 1. First-touch attribution: Which campaigns started journeys?\n",
    "# 2. Last-touch attribution: Which campaigns closed conversions?\n",
    "# 3. Multi-touch: Which campaigns appeared in customer journeys?\n",
    "# 4. For each campaign, calculate:\n",
    "#    - First-touch attribution count\n",
    "#    - Last-touch attribution count\n",
    "#    - Assist count (appeared but not first/last)\n",
    "#    - Total touchpoint appearances\n",
    "#\n",
    "# Use window functions to identify first/last in journey\n",
    "# Compare first-touch vs last-touch attribution models\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Multi-Touch Attribution Analysis:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Cohort Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a cohort analysis by campaign start month:\n",
    "# 1. Group campaigns by start month\n",
    "# 2. For each cohort (start month), calculate:\n",
    "#    - Number of campaigns launched\n",
    "#    - Average ROAS\n",
    "#    - Total spend\n",
    "#    - Total conversions\n",
    "#    - Success rate (% of campaigns with ROAS > 3.0)\n",
    "# 3. Compare cohorts to identify seasonal patterns\n",
    "#\n",
    "# Use date functions and CTEs\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Campaign Launch Cohort Analysis:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Executive Summary Dashboard Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a single comprehensive executive dashboard query using CTEs:\n",
    "#\n",
    "# Include:\n",
    "# - Overall portfolio metrics (spend, revenue, ROAS, conversions)\n",
    "# - Top 3 campaigns by ROAS with their metrics\n",
    "# - Bottom 3 campaigns needing attention\n",
    "# - Channel performance summary\n",
    "# - Week-over-week trend (last week vs previous week)\n",
    "# - Key recommendations based on data\n",
    "#\n",
    "# This should be production-ready SQL that could run daily\n",
    "# Use CTEs to organize different sections\n",
    "# Make output clear and actionable\n",
    "\n",
    "query = '''\n",
    "\n",
    "'''\n",
    "\n",
    "# result = pd.read_sql_query(query, conn)\n",
    "# print(\"Executive Dashboard:\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Week 4 Complete!\n",
    "\n",
    "**Congratulations!** You've completed Week 4 of the Marketing Measurement Partner Academy.\n",
    "\n",
    "**What You've Mastered:**\n",
    "- âœ… Advanced window functions (LAG, LEAD, NTILE, PERCENT_RANK)\n",
    "- âœ… Common Table Expressions (CTEs) for readable queries\n",
    "- âœ… Query optimization techniques\n",
    "- âœ… Date/time operations for cohort analysis\n",
    "- âœ… String manipulation for campaign parsing\n",
    "- âœ… Advanced joins and set operations\n",
    "- âœ… Production-ready marketing analytics queries\n",
    "\n",
    "**Your Advanced SQL Toolkit:**\n",
    "You can now:\n",
    "- Build complex, multi-stage analytical queries\n",
    "- Perform sophisticated time-based analyses\n",
    "- Calculate trends, moving averages, and cumulative metrics\n",
    "- Compare performance across dimensions and time\n",
    "- Create production-ready dashboards and reports\n",
    "- Optimize queries for large datasets\n",
    "\n",
    "**Next Week Preview:**\n",
    "Week 5 will cover **Exploratory Data Analysis (EDA) Fundamentals**:\n",
    "- Descriptive statistics\n",
    "- Distribution analysis and outlier detection\n",
    "- Correlation analysis\n",
    "- Data profiling\n",
    "- Segmentation and cohort analysis\n",
    "- Campaign EDA project\n",
    "\n",
    "**You're building professional-grade analytics skills!** ðŸš€\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
