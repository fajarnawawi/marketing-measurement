{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11: Advanced Incrementality Testing Platform\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement scalable geo-lift analysis\n",
    "- Build automated matched market selection systems\n",
    "- Apply synthetic control methods at scale\n",
    "- Perform causal impact analysis with large time series\n",
    "- Create incrementality monitoring dashboards\n",
    "- Design production deployment patterns\n",
    "- Build end-to-end incrementality measurement platforms\n",
    "- Handle power analysis and sample size calculations\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install pandas numpy scipy statsmodels\n",
    "pip install scikit-learn causalimpact\n",
    "pip install plotly seaborn matplotlib\n",
    "pip install cvxpy pymc3 arviz\n",
    "pip install psycopg2-binary sqlalchemy\n",
    "pip install fastapi uvicorn redis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import cvxpy as cp\n",
    "\n",
    "# Causal inference\n",
    "try:\n",
    "    from causalimpact import CausalImpact\n",
    "except:\n",
    "    print(\"CausalImpact not available - install with: pip install causalimpact\")\n",
    "\n",
    "# Database\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"SciPy: {stats.__version__}\")\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scalable Geo-Lift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoLiftAnalyzer:\n",
    "    \"\"\"Scalable geo-lift test analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.results = {}\n",
    "    \n",
    "    def calculate_lift(self,\n",
    "                      treatment_pre: np.ndarray,\n",
    "                      treatment_post: np.ndarray,\n",
    "                      control_pre: np.ndarray,\n",
    "                      control_post: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate geo-lift using difference-in-differences.\n",
    "        \n",
    "        Args:\n",
    "            treatment_pre: Treatment geo metrics before test\n",
    "            treatment_post: Treatment geo metrics during test\n",
    "            control_pre: Control geo metrics before test\n",
    "            control_post: Control geo metrics during test\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate means\n",
    "        treatment_pre_mean = treatment_pre.mean()\n",
    "        treatment_post_mean = treatment_post.mean()\n",
    "        control_pre_mean = control_pre.mean()\n",
    "        control_post_mean = control_post.mean()\n",
    "        \n",
    "        # Difference-in-differences\n",
    "        treatment_diff = treatment_post_mean - treatment_pre_mean\n",
    "        control_diff = control_post_mean - control_pre_mean\n",
    "        did_estimate = treatment_diff - control_diff\n",
    "        \n",
    "        # Percentage lift\n",
    "        expected_treatment_post = treatment_pre_mean * (control_post_mean / control_pre_mean)\n",
    "        pct_lift = (treatment_post_mean - expected_treatment_post) / expected_treatment_post * 100\n",
    "        \n",
    "        # Statistical significance\n",
    "        t_stat, p_value = stats.ttest_ind(treatment_post, control_post)\n",
    "        \n",
    "        # Confidence interval\n",
    "        treatment_se = treatment_post.std() / np.sqrt(len(treatment_post))\n",
    "        control_se = control_post.std() / np.sqrt(len(control_post))\n",
    "        se_diff = np.sqrt(treatment_se**2 + control_se**2)\n",
    "        \n",
    "        ci_lower = did_estimate - 1.96 * se_diff\n",
    "        ci_upper = did_estimate + 1.96 * se_diff\n",
    "        \n",
    "        return {\n",
    "            'did_estimate': did_estimate,\n",
    "            'pct_lift': pct_lift,\n",
    "            'treatment_pre_mean': treatment_pre_mean,\n",
    "            'treatment_post_mean': treatment_post_mean,\n",
    "            'control_pre_mean': control_pre_mean,\n",
    "            'control_post_mean': control_post_mean,\n",
    "            'p_value': p_value,\n",
    "            'is_significant': p_value < 0.05,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            't_statistic': t_stat\n",
    "        }\n",
    "    \n",
    "    def parallel_trends_test(self,\n",
    "                            treatment_pre: pd.DataFrame,\n",
    "                            control_pre: pd.DataFrame,\n",
    "                            date_col: str,\n",
    "                            metric_col: str) -> Dict:\n",
    "        \"\"\"Test parallel trends assumption.\"\"\"\n",
    "        \n",
    "        self.logger.info(\"Testing parallel trends assumption\")\n",
    "        \n",
    "        # Calculate trends\n",
    "        treatment_trend = self._calculate_trend(treatment_pre, date_col, metric_col)\n",
    "        control_trend = self._calculate_trend(control_pre, date_col, metric_col)\n",
    "        \n",
    "        # Compare slopes\n",
    "        slope_diff = abs(treatment_trend['slope'] - control_trend['slope'])\n",
    "        \n",
    "        # Test if trends are parallel (slopes are similar)\n",
    "        # Using F-test for equality of regression coefficients\n",
    "        is_parallel = slope_diff < 0.1 * abs(control_trend['slope'])\n",
    "        \n",
    "        return {\n",
    "            'treatment_slope': treatment_trend['slope'],\n",
    "            'control_slope': control_trend['slope'],\n",
    "            'slope_difference': slope_diff,\n",
    "            'is_parallel': is_parallel,\n",
    "            'treatment_r2': treatment_trend['r2'],\n",
    "            'control_r2': control_trend['r2']\n",
    "        }\n",
    "    \n",
    "    def _calculate_trend(self, df: pd.DataFrame, date_col: str, metric_col: str) -> Dict:\n",
    "        \"\"\"Calculate linear trend.\"\"\"\n",
    "        \n",
    "        df = df.copy()\n",
    "        df['time_idx'] = (df[date_col] - df[date_col].min()).dt.days\n",
    "        \n",
    "        X = df[['time_idx']].values\n",
    "        y = df[metric_col].values\n",
    "        \n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        return {\n",
    "            'slope': model.params[1],\n",
    "            'intercept': model.params[0],\n",
    "            'r2': model.rsquared,\n",
    "            'p_value': model.pvalues[1]\n",
    "        }\n",
    "    \n",
    "    def power_analysis(self,\n",
    "                      baseline_mean: float,\n",
    "                      baseline_std: float,\n",
    "                      min_detectable_effect: float,\n",
    "                      alpha: float = 0.05,\n",
    "                      power: float = 0.8) -> int:\n",
    "        \"\"\"Calculate required sample size for given power.\n",
    "        \n",
    "        Args:\n",
    "            baseline_mean: Expected baseline metric value\n",
    "            baseline_std: Standard deviation of metric\n",
    "            min_detectable_effect: Minimum lift to detect (as pct)\n",
    "            alpha: Significance level\n",
    "            power: Desired statistical power\n",
    "        \"\"\"\n",
    "        \n",
    "        effect_size = (baseline_mean * min_detectable_effect / 100) / baseline_std\n",
    "        \n",
    "        # Calculate required sample size\n",
    "        n = tt_ind_solve_power(\n",
    "            effect_size=effect_size,\n",
    "            alpha=alpha,\n",
    "            power=power,\n",
    "            alternative='two-sided'\n",
    "        )\n",
    "        \n",
    "        return int(np.ceil(n))\n",
    "    \n",
    "    def estimate_runtime(self,\n",
    "                        baseline_mean: float,\n",
    "                        min_detectable_effect: float,\n",
    "                        daily_variance: float,\n",
    "                        alpha: float = 0.05,\n",
    "                        power: float = 0.8) -> int:\n",
    "        \"\"\"Estimate required test duration in days.\"\"\"\n",
    "        \n",
    "        # Effect size\n",
    "        effect_size = (baseline_mean * min_detectable_effect / 100) / np.sqrt(daily_variance)\n",
    "        \n",
    "        # Critical value\n",
    "        z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "        z_beta = stats.norm.ppf(power)\n",
    "        \n",
    "        # Required days\n",
    "        n_days = int(np.ceil(((z_alpha + z_beta) / effect_size) ** 2))\n",
    "        \n",
    "        return n_days\n",
    "\n",
    "\n",
    "# Example\n",
    "analyzer = GeoLiftAnalyzer()\n",
    "print(\"Geo-lift analyzer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automated Matched Market Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedMarketSelector:\n",
    "    \"\"\"Automated selection of matched control markets.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def find_matches(self,\n",
    "                    treatment_markets: List[str],\n",
    "                    candidate_controls: List[str],\n",
    "                    market_data: pd.DataFrame,\n",
    "                    matching_features: List[str],\n",
    "                    n_matches: int = 1,\n",
    "                    method: str = 'euclidean') -> pd.DataFrame:\n",
    "        \"\"\"Find best matching control markets.\n",
    "        \n",
    "        Args:\n",
    "            treatment_markets: List of treatment market IDs\n",
    "            candidate_controls: List of candidate control market IDs\n",
    "            market_data: DataFrame with market characteristics\n",
    "            matching_features: Features to use for matching\n",
    "            n_matches: Number of control markets to select\n",
    "            method: Distance metric ('euclidean', 'cosine', 'dtw')\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Finding {n_matches} matches for {len(treatment_markets)} treatment markets\")\n",
    "        \n",
    "        # Normalize features\n",
    "        scaler = StandardScaler()\n",
    "        market_data[matching_features] = scaler.fit_transform(market_data[matching_features])\n",
    "        \n",
    "        # Get treatment and control data\n",
    "        treatment_data = market_data[market_data.index.isin(treatment_markets)]\n",
    "        control_data = market_data[market_data.index.isin(candidate_controls)]\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        for treatment_market in treatment_markets:\n",
    "            treatment_features = treatment_data.loc[treatment_market, matching_features].values\n",
    "            \n",
    "            # Calculate distances to all controls\n",
    "            distances = []\n",
    "            for control_market in candidate_controls:\n",
    "                control_features = control_data.loc[control_market, matching_features].values\n",
    "                \n",
    "                if method == 'euclidean':\n",
    "                    dist = euclidean(treatment_features, control_features)\n",
    "                elif method == 'cosine':\n",
    "                    dist = cosine(treatment_features, control_features)\n",
    "                elif method == 'dtw':\n",
    "                    dist = self._dtw_distance(treatment_features, control_features)\n",
    "                \n",
    "                distances.append({\n",
    "                    'treatment': treatment_market,\n",
    "                    'control': control_market,\n",
    "                    'distance': dist\n",
    "                })\n",
    "            \n",
    "            # Select top matches\n",
    "            distances_df = pd.DataFrame(distances).sort_values('distance')\n",
    "            top_matches = distances_df.head(n_matches)\n",
    "            matches.append(top_matches)\n",
    "        \n",
    "        return pd.concat(matches, ignore_index=True)\n",
    "    \n",
    "    def _dtw_distance(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Dynamic Time Warping distance.\"\"\"\n",
    "        \n",
    "        n, m = len(x), len(y)\n",
    "        dtw = np.zeros((n+1, m+1))\n",
    "        dtw[0, :] = np.inf\n",
    "        dtw[:, 0] = np.inf\n",
    "        dtw[0, 0] = 0\n",
    "        \n",
    "        for i in range(1, n+1):\n",
    "            for j in range(1, m+1):\n",
    "                cost = abs(x[i-1] - y[j-1])\n",
    "                dtw[i, j] = cost + min(dtw[i-1, j], dtw[i, j-1], dtw[i-1, j-1])\n",
    "        \n",
    "        return dtw[n, m]\n",
    "    \n",
    "    def validate_matches(self,\n",
    "                        matches: pd.DataFrame,\n",
    "                        market_data: pd.DataFrame,\n",
    "                        time_series_col: str,\n",
    "                        metric_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Validate quality of matched markets.\"\"\"\n",
    "        \n",
    "        validation_results = []\n",
    "        \n",
    "        for _, match in matches.iterrows():\n",
    "            treatment = match['treatment']\n",
    "            control = match['control']\n",
    "            \n",
    "            # Get time series\n",
    "            treatment_ts = market_data[market_data['market'] == treatment][metric_col].values\n",
    "            control_ts = market_data[market_data['market'] == control][metric_col].values\n",
    "            \n",
    "            # Calculate correlation\n",
    "            correlation = np.corrcoef(treatment_ts, control_ts)[0, 1]\n",
    "            \n",
    "            # Test for cointegration\n",
    "            try:\n",
    "                adf_stat, adf_pvalue, _, _, _, _ = adfuller(treatment_ts - control_ts)\n",
    "                is_cointegrated = adf_pvalue < 0.05\n",
    "            except:\n",
    "                is_cointegrated = False\n",
    "            \n",
    "            # MAPE between series\n",
    "            mape = np.mean(np.abs((treatment_ts - control_ts) / treatment_ts)) * 100\n",
    "            \n",
    "            validation_results.append({\n",
    "                'treatment': treatment,\n",
    "                'control': control,\n",
    "                'correlation': correlation,\n",
    "                'is_cointegrated': is_cointegrated,\n",
    "                'mape': mape,\n",
    "                'match_quality': 'Excellent' if correlation > 0.9 else ('Good' if correlation > 0.7 else 'Fair')\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(validation_results)\n",
    "    \n",
    "    def optimize_match_selection(self,\n",
    "                                 treatment_markets: List[str],\n",
    "                                 candidate_controls: List[str],\n",
    "                                 market_data: pd.DataFrame,\n",
    "                                 metric_col: str,\n",
    "                                 max_controls: int = 5) -> List[str]:\n",
    "        \"\"\"Optimize selection of control group using integer programming.\"\"\"\n",
    "        \n",
    "        n_candidates = len(candidate_controls)\n",
    "        \n",
    "        # Decision variables (binary: include control or not)\n",
    "        x = cp.Variable(n_candidates, boolean=True)\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarities = []\n",
    "        for control in candidate_controls:\n",
    "            treatment_avg = market_data[market_data.index.isin(treatment_markets)][metric_col].mean()\n",
    "            control_val = market_data.loc[control, metric_col]\n",
    "            similarity = 1 / (1 + abs(treatment_avg - control_val))\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        # Objective: maximize total similarity\n",
    "        objective = cp.Maximize(cp.sum(cp.multiply(similarities, x)))\n",
    "        \n",
    "        # Constraints\n",
    "        constraints = [\n",
    "            cp.sum(x) <= max_controls,  # Max number of controls\n",
    "            cp.sum(x) >= 1  # At least one control\n",
    "        ]\n",
    "        \n",
    "        # Solve\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        \n",
    "        # Get selected controls\n",
    "        selected_idx = np.where(x.value > 0.5)[0]\n",
    "        selected_controls = [candidate_controls[i] for i in selected_idx]\n",
    "        \n",
    "        return selected_controls\n",
    "\n",
    "\n",
    "selector = MatchedMarketSelector()\n",
    "print(\"Matched market selector ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Control at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticControl:\n",
    "    \"\"\"Synthetic control method for causal inference.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.weights = None\n",
    "        self.synthetic_control = None\n",
    "    \n",
    "    def fit(self,\n",
    "           treatment_pre: np.ndarray,\n",
    "           control_pre: np.ndarray,\n",
    "           method: str = 'standard') -> np.ndarray:\n",
    "        \"\"\"Fit synthetic control using donor pool.\n",
    "        \n",
    "        Args:\n",
    "            treatment_pre: Pre-intervention treatment unit data (T x 1)\n",
    "            control_pre: Pre-intervention control units data (T x N)\n",
    "            method: 'standard', 'ridge', or 'elastic_net'\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Fitting synthetic control with {method} method\")\n",
    "        \n",
    "        if method == 'standard':\n",
    "            self.weights = self._fit_standard(treatment_pre, control_pre)\n",
    "        elif method == 'ridge':\n",
    "            self.weights = self._fit_ridge(treatment_pre, control_pre)\n",
    "        elif method == 'elastic_net':\n",
    "            self.weights = self._fit_elastic_net(treatment_pre, control_pre)\n",
    "        \n",
    "        # Create synthetic control\n",
    "        self.synthetic_control = control_pre @ self.weights\n",
    "        \n",
    "        return self.weights\n",
    "    \n",
    "    def _fit_standard(self, treatment: np.ndarray, controls: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Standard synthetic control (quadratic programming).\"\"\"\n",
    "        \n",
    "        n_controls = controls.shape[1]\n",
    "        \n",
    "        # Decision variables\n",
    "        w = cp.Variable(n_controls)\n",
    "        \n",
    "        # Objective: minimize squared difference\n",
    "        objective = cp.Minimize(cp.sum_squares(treatment - controls @ w))\n",
    "        \n",
    "        # Constraints: weights sum to 1 and are non-negative\n",
    "        constraints = [\n",
    "            cp.sum(w) == 1,\n",
    "            w >= 0\n",
    "        ]\n",
    "        \n",
    "        # Solve\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        \n",
    "        return w.value\n",
    "    \n",
    "    def _fit_ridge(self, treatment: np.ndarray, controls: np.ndarray, alpha: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"Synthetic control with ridge regularization.\"\"\"\n",
    "        \n",
    "        n_controls = controls.shape[1]\n",
    "        w = cp.Variable(n_controls)\n",
    "        \n",
    "        objective = cp.Minimize(\n",
    "            cp.sum_squares(treatment - controls @ w) +\n",
    "            alpha * cp.sum_squares(w)\n",
    "        )\n",
    "        \n",
    "        constraints = [cp.sum(w) == 1, w >= 0]\n",
    "        \n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        \n",
    "        return w.value\n",
    "    \n",
    "    def _fit_elastic_net(self, treatment: np.ndarray, controls: np.ndarray,\n",
    "                        alpha: float = 1.0, l1_ratio: float = 0.5) -> np.ndarray:\n",
    "        \"\"\"Synthetic control with elastic net regularization.\"\"\"\n",
    "        \n",
    "        n_controls = controls.shape[1]\n",
    "        w = cp.Variable(n_controls)\n",
    "        \n",
    "        objective = cp.Minimize(\n",
    "            cp.sum_squares(treatment - controls @ w) +\n",
    "            alpha * l1_ratio * cp.norm(w, 1) +\n",
    "            alpha * (1 - l1_ratio) * cp.sum_squares(w)\n",
    "        )\n",
    "        \n",
    "        constraints = [cp.sum(w) == 1, w >= 0]\n",
    "        \n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        \n",
    "        return w.value\n",
    "    \n",
    "    def predict(self, control_post: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict counterfactual for post-intervention period.\"\"\"\n",
    "        \n",
    "        if self.weights is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "        \n",
    "        return control_post @ self.weights\n",
    "    \n",
    "    def calculate_effect(self,\n",
    "                        treatment_post: np.ndarray,\n",
    "                        control_post: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate treatment effect.\"\"\"\n",
    "        \n",
    "        # Counterfactual\n",
    "        counterfactual = self.predict(control_post)\n",
    "        \n",
    "        # Effect\n",
    "        effect = treatment_post - counterfactual\n",
    "        \n",
    "        # Statistics\n",
    "        avg_effect = effect.mean()\n",
    "        cumulative_effect = effect.sum()\n",
    "        pct_effect = (avg_effect / counterfactual.mean()) * 100\n",
    "        \n",
    "        return {\n",
    "            'treatment': treatment_post,\n",
    "            'counterfactual': counterfactual,\n",
    "            'effect': effect,\n",
    "            'avg_effect': avg_effect,\n",
    "            'cumulative_effect': cumulative_effect,\n",
    "            'pct_effect': pct_effect\n",
    "        }\n",
    "    \n",
    "    def placebo_test(self,\n",
    "                    treatment_pre: np.ndarray,\n",
    "                    control_pre: np.ndarray,\n",
    "                    n_placebos: int = 100) -> Dict:\n",
    "        \"\"\"Perform placebo tests for inference.\"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Running {n_placebos} placebo tests\")\n",
    "        \n",
    "        n_controls = control_pre.shape[1]\n",
    "        placebo_effects = []\n",
    "        \n",
    "        for i in range(n_controls):\n",
    "            # Use control i as placebo treatment\n",
    "            placebo_treatment = control_pre[:, i]\n",
    "            placebo_controls = np.delete(control_pre, i, axis=1)\n",
    "            \n",
    "            # Fit synthetic control\n",
    "            try:\n",
    "                weights = self._fit_standard(placebo_treatment, placebo_controls)\n",
    "                synthetic = placebo_controls @ weights\n",
    "                effect = placebo_treatment - synthetic\n",
    "                placebo_effects.append(effect.mean())\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        placebo_effects = np.array(placebo_effects)\n",
    "        \n",
    "        # Calculate p-value\n",
    "        actual_effect = (treatment_pre - self.synthetic_control).mean()\n",
    "        p_value = np.mean(np.abs(placebo_effects) >= np.abs(actual_effect))\n",
    "        \n",
    "        return {\n",
    "            'placebo_effects': placebo_effects,\n",
    "            'actual_effect': actual_effect,\n",
    "            'p_value': p_value,\n",
    "            'is_significant': p_value < 0.05\n",
    "        }\n",
    "    \n",
    "    def get_donor_weights(self) -> pd.DataFrame:\n",
    "        \"\"\"Get donor unit weights.\"\"\"\n",
    "        \n",
    "        if self.weights is None:\n",
    "            raise ValueError(\"Model not fitted\")\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'donor_id': range(len(self.weights)),\n",
    "            'weight': self.weights\n",
    "        }).sort_values('weight', ascending=False)\n",
    "\n",
    "\n",
    "sc = SyntheticControl()\n",
    "print(\"Synthetic control ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Causal Impact with Large Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImpactAnalyzer:\n",
    "    \"\"\"Scalable causal impact analysis using Bayesian structural time series.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.model = None\n",
    "        self.results = None\n",
    "    \n",
    "    def analyze(self,\n",
    "               data: pd.DataFrame,\n",
    "               pre_period: Tuple[str, str],\n",
    "               post_period: Tuple[str, str],\n",
    "               response_col: str,\n",
    "               covariate_cols: Optional[List[str]] = None) -> Dict:\n",
    "        \"\"\"Perform causal impact analysis.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data with DatetimeIndex\n",
    "            pre_period: (start, end) dates for pre-intervention\n",
    "            post_period: (start, end) dates for post-intervention\n",
    "            response_col: Name of response variable\n",
    "            covariate_cols: Optional control variables\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.info(\"Running causal impact analysis\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare data\n",
    "            if covariate_cols:\n",
    "                data_formatted = data[[response_col] + covariate_cols]\n",
    "            else:\n",
    "                data_formatted = data[[response_col]]\n",
    "            \n",
    "            # Run CausalImpact\n",
    "            ci = CausalImpact(data_formatted, pre_period, post_period)\n",
    "            \n",
    "            # Extract results\n",
    "            summary = ci.summary()\n",
    "            summary_data = ci.summary_data\n",
    "            \n",
    "            self.results = {\n",
    "                'average_effect': summary_data['average']['actual'] - summary_data['average']['predicted'],\n",
    "                'cumulative_effect': summary_data['cumulative']['actual'] - summary_data['cumulative']['predicted'],\n",
    "                'relative_effect': summary_data['average']['rel_effect'],\n",
    "                'p_value': summary_data['average']['p'],\n",
    "                'lower_95': summary_data['average']['actual_lower'],\n",
    "                'upper_95': summary_data['average']['actual_upper'],\n",
    "                'is_significant': summary_data['average']['p'] < 0.05,\n",
    "                'model': ci\n",
    "            }\n",
    "            \n",
    "            return self.results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"CausalImpact analysis failed: {e}\")\n",
    "            return self._fallback_analysis(data, pre_period, post_period, response_col)\n",
    "    \n",
    "    def _fallback_analysis(self,\n",
    "                          data: pd.DataFrame,\n",
    "                          pre_period: Tuple[str, str],\n",
    "                          post_period: Tuple[str, str],\n",
    "                          response_col: str) -> Dict:\n",
    "        \"\"\"Fallback to simple analysis if CausalImpact fails.\"\"\"\n",
    "        \n",
    "        pre_data = data.loc[pre_period[0]:pre_period[1], response_col]\n",
    "        post_data = data.loc[post_period[0]:post_period[1], response_col]\n",
    "        \n",
    "        # Simple difference\n",
    "        avg_effect = post_data.mean() - pre_data.mean()\n",
    "        cumulative_effect = post_data.sum() - (pre_data.mean() * len(post_data))\n",
    "        relative_effect = avg_effect / pre_data.mean() * 100\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = stats.ttest_ind(post_data, pre_data)\n",
    "        \n",
    "        return {\n",
    "            'average_effect': avg_effect,\n",
    "            'cumulative_effect': cumulative_effect,\n",
    "            'relative_effect': relative_effect,\n",
    "            'p_value': p_value,\n",
    "            'is_significant': p_value < 0.05,\n",
    "            'method': 'fallback'\n",
    "        }\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"Plot causal impact results.\"\"\"\n",
    "        \n",
    "        if self.results and 'model' in self.results:\n",
    "            self.results['model'].plot()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "ci_analyzer = CausalImpactAnalyzer()\n",
    "print(\"Causal impact analyzer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Incrementality Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalityDashboard:\n",
    "    \"\"\"Real-time incrementality monitoring dashboard.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_config: Dict):\n",
    "        self.db_config = db_config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.engine = create_engine(\n",
    "            f\"postgresql://{db_config['user']}:{db_config['password']}@\"\n",
    "            f\"{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n",
    "        )\n",
    "    \n",
    "    def get_active_tests(self) -> pd.DataFrame:\n",
    "        \"\"\"Get all active incrementality tests.\"\"\"\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            test_id,\n",
    "            test_name,\n",
    "            channel,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            status,\n",
    "            treatment_markets,\n",
    "            control_markets\n",
    "        FROM incrementality_tests\n",
    "        WHERE status = 'active'\n",
    "        ORDER BY start_date DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        return pd.read_sql(query, self.engine)\n",
    "    \n",
    "    def get_test_metrics(self, test_id: str, current_date: str) -> Dict:\n",
    "        \"\"\"Get real-time metrics for a test.\"\"\"\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            market_id,\n",
    "            is_treatment,\n",
    "            revenue,\n",
    "            conversions,\n",
    "            spend\n",
    "        FROM test_daily_metrics\n",
    "        WHERE test_id = '{test_id}'\n",
    "          AND date <= '{current_date}'\n",
    "        ORDER BY date, market_id\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.read_sql(query, self.engine)\n",
    "        \n",
    "        # Calculate running metrics\n",
    "        treatment = data[data['is_treatment']]\n",
    "        control = data[~data['is_treatment']]\n",
    "        \n",
    "        metrics = {\n",
    "            'treatment_revenue': treatment['revenue'].sum(),\n",
    "            'control_revenue': control['revenue'].sum(),\n",
    "            'treatment_conversions': treatment['conversions'].sum(),\n",
    "            'control_conversions': control['conversions'].sum(),\n",
    "            'treatment_spend': treatment['spend'].sum(),\n",
    "            'days_running': data['date'].nunique()\n",
    "        }\n",
    "        \n",
    "        # Calculate lift\n",
    "        treatment_avg = metrics['treatment_revenue'] / metrics['days_running']\n",
    "        control_avg = metrics['control_revenue'] / metrics['days_running']\n",
    "        metrics['lift_pct'] = (treatment_avg - control_avg) / control_avg * 100\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def create_dashboard(self, test_id: str) -> go.Figure:\n",
    "        \"\"\"Create interactive dashboard for a test.\"\"\"\n",
    "        \n",
    "        # Get data\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            SUM(CASE WHEN is_treatment THEN revenue ELSE 0 END) as treatment_revenue,\n",
    "            SUM(CASE WHEN NOT is_treatment THEN revenue ELSE 0 END) as control_revenue\n",
    "        FROM test_daily_metrics\n",
    "        WHERE test_id = '{test_id}'\n",
    "        GROUP BY date\n",
    "        ORDER BY date\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.read_sql(query, self.engine)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=[\n",
    "                'Revenue Over Time',\n",
    "                'Cumulative Revenue',\n",
    "                'Daily Lift %',\n",
    "                'Confidence Intervals'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Revenue over time\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data['date'], y=data['treatment_revenue'], \n",
    "                      name='Treatment', line=dict(color='blue')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data['date'], y=data['control_revenue'],\n",
    "                      name='Control', line=dict(color='orange')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Cumulative revenue\n",
    "        data['treatment_cumsum'] = data['treatment_revenue'].cumsum()\n",
    "        data['control_cumsum'] = data['control_revenue'].cumsum()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data['date'], y=data['treatment_cumsum'],\n",
    "                      name='Treatment Cumulative', line=dict(color='blue')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data['date'], y=data['control_cumsum'],\n",
    "                      name='Control Cumulative', line=dict(color='orange')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Daily lift\n",
    "        data['lift'] = (data['treatment_revenue'] - data['control_revenue']) / data['control_revenue'] * 100\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data['date'], y=data['lift'],\n",
    "                      name='Lift %', line=dict(color='green')),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=2, col=1)\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=True, title_text=f\"Test {test_id} Dashboard\")\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def alert_check(self, test_id: str) -> List[Dict]:\n",
    "        \"\"\"Check for alerts and anomalies.\"\"\"\n",
    "        \n",
    "        alerts = []\n",
    "        \n",
    "        metrics = self.get_test_metrics(test_id, datetime.now().strftime('%Y-%m-%d'))\n",
    "        \n",
    "        # Check for negative lift\n",
    "        if metrics['lift_pct'] < -5:\n",
    "            alerts.append({\n",
    "                'severity': 'high',\n",
    "                'message': f\"Negative lift detected: {metrics['lift_pct']:.1f}%\",\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        # Check for data quality\n",
    "        if metrics['treatment_revenue'] == 0 or metrics['control_revenue'] == 0:\n",
    "            alerts.append({\n",
    "                'severity': 'critical',\n",
    "                'message': 'Missing data detected',\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        return alerts\n",
    "\n",
    "\n",
    "print(\"Incrementality dashboard ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-World Project: Build Incrementality Measurement Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalityPlatform:\n",
    "    \"\"\"End-to-end incrementality measurement platform.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "        # Initialize components\n",
    "        self.selector = MatchedMarketSelector()\n",
    "        self.analyzer = GeoLiftAnalyzer()\n",
    "        self.sc = SyntheticControl()\n",
    "        self.ci_analyzer = CausalImpactAnalyzer()\n",
    "    \n",
    "    def design_test(self,\n",
    "                   channel: str,\n",
    "                   markets_data: pd.DataFrame,\n",
    "                   n_treatment: int,\n",
    "                   n_control: int,\n",
    "                   min_detectable_effect: float = 10.0) -> Dict:\n",
    "        \"\"\"Design incrementality test.\"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Designing test for {channel}\")\n",
    "        \n",
    "        # 1. Calculate required sample size\n",
    "        baseline_mean = markets_data['revenue'].mean()\n",
    "        baseline_std = markets_data['revenue'].std()\n",
    "        \n",
    "        required_markets = self.analyzer.power_analysis(\n",
    "            baseline_mean=baseline_mean,\n",
    "            baseline_std=baseline_std,\n",
    "            min_detectable_effect=min_detectable_effect\n",
    "        )\n",
    "        \n",
    "        # 2. Select treatment markets (random or stratified)\n",
    "        treatment_markets = markets_data.sample(n=n_treatment)['market_id'].tolist()\n",
    "        \n",
    "        # 3. Find matched controls\n",
    "        candidate_controls = markets_data[\n",
    "            ~markets_data['market_id'].isin(treatment_markets)\n",
    "        ]['market_id'].tolist()\n",
    "        \n",
    "        matches = self.selector.find_matches(\n",
    "            treatment_markets=treatment_markets,\n",
    "            candidate_controls=candidate_controls,\n",
    "            market_data=markets_data,\n",
    "            matching_features=['population', 'income', 'competition_index'],\n",
    "            n_matches=n_control\n",
    "        )\n",
    "        \n",
    "        control_markets = matches['control'].unique().tolist()\n",
    "        \n",
    "        # 4. Validate matches\n",
    "        validation = self.selector.validate_matches(\n",
    "            matches=matches,\n",
    "            market_data=markets_data,\n",
    "            time_series_col='date',\n",
    "            metric_col='revenue'\n",
    "        )\n",
    "        \n",
    "        # 5. Estimate test duration\n",
    "        duration = self.analyzer.estimate_runtime(\n",
    "            baseline_mean=baseline_mean,\n",
    "            min_detectable_effect=min_detectable_effect,\n",
    "            daily_variance=markets_data.groupby('date')['revenue'].var().mean()\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'test_design': {\n",
    "                'channel': channel,\n",
    "                'treatment_markets': treatment_markets,\n",
    "                'control_markets': control_markets,\n",
    "                'required_markets': required_markets,\n",
    "                'estimated_duration_days': duration,\n",
    "                'min_detectable_effect': min_detectable_effect\n",
    "            },\n",
    "            'validation': validation,\n",
    "            'matches': matches\n",
    "        }\n",
    "    \n",
    "    def execute_test(self, test_design: Dict, start_date: str, end_date: str):\n",
    "        \"\"\"Execute incrementality test.\"\"\"\n",
    "        \n",
    "        self.logger.info(\"Executing incrementality test\")\n",
    "        \n",
    "        # Store test in database\n",
    "        test_id = self._create_test_record(test_design, start_date, end_date)\n",
    "        \n",
    "        # Monitor test\n",
    "        self._setup_monitoring(test_id)\n",
    "        \n",
    "        return test_id\n",
    "    \n",
    "    def analyze_results(self,\n",
    "                       test_id: str,\n",
    "                       data: pd.DataFrame,\n",
    "                       method: str = 'all') -> Dict:\n",
    "        \"\"\"Analyze test results using multiple methods.\"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Analyzing test {test_id} with method: {method}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Prepare data\n",
    "        treatment_data = data[data['is_treatment']]\n",
    "        control_data = data[~data['is_treatment']]\n",
    "        \n",
    "        # Method 1: Difference-in-differences\n",
    "        if method in ['all', 'did']:\n",
    "            did_results = self.analyzer.calculate_lift(\n",
    "                treatment_pre=treatment_data[treatment_data['period'] == 'pre']['revenue'].values,\n",
    "                treatment_post=treatment_data[treatment_data['period'] == 'post']['revenue'].values,\n",
    "                control_pre=control_data[control_data['period'] == 'pre']['revenue'].values,\n",
    "                control_post=control_data[control_data['period'] == 'post']['revenue'].values\n",
    "            )\n",
    "            results['difference_in_differences'] = did_results\n",
    "        \n",
    "        # Method 2: Synthetic control\n",
    "        if method in ['all', 'synthetic_control']:\n",
    "            treatment_pre = treatment_data[treatment_data['period'] == 'pre']['revenue'].values\n",
    "            control_pre = control_data[control_data['period'] == 'pre'].pivot(\n",
    "                index='date', columns='market_id', values='revenue'\n",
    "            ).values\n",
    "            \n",
    "            self.sc.fit(treatment_pre, control_pre)\n",
    "            \n",
    "            control_post = control_data[control_data['period'] == 'post'].pivot(\n",
    "                index='date', columns='market_id', values='revenue'\n",
    "            ).values\n",
    "            treatment_post = treatment_data[treatment_data['period'] == 'post']['revenue'].values\n",
    "            \n",
    "            sc_results = self.sc.calculate_effect(treatment_post, control_post)\n",
    "            results['synthetic_control'] = sc_results\n",
    "        \n",
    "        # Method 3: Causal Impact\n",
    "        if method in ['all', 'causal_impact']:\n",
    "            ci_results = self.ci_analyzer.analyze(\n",
    "                data=data.set_index('date'),\n",
    "                pre_period=(data[data['period'] == 'pre']['date'].min(),\n",
    "                           data[data['period'] == 'pre']['date'].max()),\n",
    "                post_period=(data[data['period'] == 'post']['date'].min(),\n",
    "                            data[data['period'] == 'post']['date'].max()),\n",
    "                response_col='revenue'\n",
    "            )\n",
    "            results['causal_impact'] = ci_results\n",
    "        \n",
    "        # Consensus result\n",
    "        results['consensus'] = self._calculate_consensus(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_consensus(self, results: Dict) -> Dict:\n",
    "        \"\"\"Calculate consensus estimate across methods.\"\"\"\n",
    "        \n",
    "        effects = []\n",
    "        \n",
    "        if 'difference_in_differences' in results:\n",
    "            effects.append(results['difference_in_differences']['pct_lift'])\n",
    "        \n",
    "        if 'synthetic_control' in results:\n",
    "            effects.append(results['synthetic_control']['pct_effect'])\n",
    "        \n",
    "        if 'causal_impact' in results:\n",
    "            effects.append(results['causal_impact']['relative_effect'])\n",
    "        \n",
    "        return {\n",
    "            'mean_effect': np.mean(effects),\n",
    "            'median_effect': np.median(effects),\n",
    "            'std_effect': np.std(effects),\n",
    "            'min_effect': np.min(effects),\n",
    "            'max_effect': np.max(effects)\n",
    "        }\n",
    "    \n",
    "    def _create_test_record(self, test_design: Dict, start_date: str, end_date: str) -> str:\n",
    "        \"\"\"Create test record in database.\"\"\"\n",
    "        # Implementation would insert into database\n",
    "        test_id = f\"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        return test_id\n",
    "    \n",
    "    def _setup_monitoring(self, test_id: str):\n",
    "        \"\"\"Setup real-time monitoring for test.\"\"\"\n",
    "        # Implementation would setup monitoring\n",
    "        pass\n",
    "    \n",
    "    def generate_report(self, test_id: str, results: Dict) -> str:\n",
    "        \"\"\"Generate executive report.\"\"\"\n",
    "        \n",
    "        consensus = results['consensus']\n",
    "        \n",
    "        report = f\"\"\"\n",
    "        INCREMENTALITY TEST RESULTS\n",
    "        ==========================\n",
    "        \n",
    "        Test ID: {test_id}\n",
    "        Date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "        \n",
    "        SUMMARY:\n",
    "        --------\n",
    "        Consensus Lift: {consensus['mean_effect']:.1f}%\n",
    "        Range: {consensus['min_effect']:.1f}% to {consensus['max_effect']:.1f}%\n",
    "        \n",
    "        METHODOLOGY COMPARISON:\n",
    "        ----------------------\n",
    "        \"\"\"  \n",
    "        \n",
    "        if 'difference_in_differences' in results:\n",
    "            did = results['difference_in_differences']\n",
    "            report += f\"\"\"\n",
    "        Difference-in-Differences:\n",
    "          - Lift: {did['pct_lift']:.1f}%\n",
    "          - P-value: {did['p_value']:.4f}\n",
    "          - Significant: {did['is_significant']}\n",
    "            \"\"\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# platform = IncrementalityPlatform(config={'db': 'connection_string'})\n",
    "# test_design = platform.design_test(\n",
    "#     channel='paid_search',\n",
    "#     markets_data=market_df,\n",
    "#     n_treatment=10,\n",
    "#     n_control=10\n",
    "# )\n",
    "\n",
    "print(\"Incrementality platform ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercises\n",
    "\n",
    "### Exercise 1: Geo-Lift Test Design\n",
    "1. Design a geo-lift test for a marketing channel\n",
    "2. Calculate required sample size for 10% MDE\n",
    "3. Estimate test duration\n",
    "4. Validate parallel trends assumption\n",
    "5. Analyze results with DID\n",
    "\n",
    "### Exercise 2: Matched Market Selection\n",
    "1. Load multi-market dataset\n",
    "2. Select treatment markets\n",
    "3. Find optimal matched controls\n",
    "4. Validate match quality\n",
    "5. Test for cointegration\n",
    "\n",
    "### Exercise 3: Synthetic Control Analysis\n",
    "1. Implement synthetic control method\n",
    "2. Fit model on pre-intervention period\n",
    "3. Calculate treatment effect\n",
    "4. Run placebo tests\n",
    "5. Visualize results\n",
    "\n",
    "### Exercise 4: Production Platform\n",
    "1. Build end-to-end incrementality platform\n",
    "2. Implement automated test design\n",
    "3. Create monitoring dashboard\n",
    "4. Set up alerting system\n",
    "5. Generate automated reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Documentation\n",
    "- [CausalImpact R Package](https://google.github.io/CausalImpact/)\n",
    "- [Synthetic Control Methods](https://synth-inference.github.io/)\n",
    "- [GeoLift (Meta)](https://facebookincubator.github.io/GeoLift/)\n",
    "- [CVXPY - Optimization](https://www.cvxpy.org/)\n",
    "\n",
    "### Papers\n",
    "- Abadie et al. (2010): Synthetic Control Methods for Comparative Case Studies\n",
    "- Brodersen et al. (2015): Inferring causal impact using Bayesian structural time-series models\n",
    "- Athey & Imbens (2017): The State of Applied Econometrics\n",
    "- Vaver & Koehler (2011): Measuring Ad Effectiveness Using Geo Experiments\n",
    "\n",
    "### Tools\n",
    "- GeoLift: Geo experimentation platform\n",
    "- CausalImpact: Bayesian causal impact\n",
    "- DoWhy: Causal inference library\n",
    "- EconML: Econometric ML methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
