{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Advanced Statistics for Big Data\n",
    "\n",
    "## Overview\n",
    "Master statistical analysis techniques for large-scale marketing data, including hypothesis testing, Bayesian methods, and time series analysis at scale.\n",
    "\n",
    "## Learning Objectives\n",
    "- Perform statistical tests on massive samples\n",
    "- Handle challenges of large sample sizes\n",
    "- Implement bootstrap and resampling at scale\n",
    "- Conduct power analysis for large experiments\n",
    "- Apply Bayesian statistics to marketing problems\n",
    "- Analyze time series data at scale\n",
    "\n",
    "## Prerequisites\n",
    "- Strong statistics foundation\n",
    "- Redshift cluster access\n",
    "- Large marketing dataset (10M+ rows)\n",
    "- Understanding of hypothesis testing\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Environment](#setup)\n",
    "2. [Statistical Tests on Large Samples](#large-samples)\n",
    "3. [Handling Massive Sample Sizes](#massive-samples)\n",
    "4. [Bootstrap and Resampling at Scale](#bootstrap)\n",
    "5. [Power Analysis for Large Experiments](#power-analysis)\n",
    "6. [Bayesian Statistics for Marketing](#bayesian)\n",
    "7. [Time Series Analysis at Scale](#timeseries)\n",
    "8. [Real-World Project: 50M Conversion Analysis](#project)\n",
    "9. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q scipy statsmodels scikit-learn\n",
    "!pip install -q pymc3 arviz  # Bayesian analysis\n",
    "!pip install -q prophet  # Time series\n",
    "!pip install -q pandas numpy redshift_connector\n",
    "!pip install -q plotly seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, beta, gamma, ttest_ind, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import redshift_connector\n",
    "from sklearn.utils import resample\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "class RedshiftStatsAnalyzer:\n",
    "    \"\"\"\n",
    "    Statistical analysis framework for Redshift data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host, port, database, user, password):\n",
    "        self.config = {\n",
    "            'host': host,\n",
    "            'port': int(port),\n",
    "            'database': database,\n",
    "            'user': user,\n",
    "            'password': password\n",
    "        }\n",
    "        self.conn = None\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection\"\"\"\n",
    "        self.conn = redshift_connector.connect(**self.config)\n",
    "        print(f\"✓ Connected to {self.config['database']}\")\n",
    "        return self.conn\n",
    "    \n",
    "    def query(self, sql):\n",
    "        \"\"\"Execute query and return DataFrame\"\"\"\n",
    "        if not self.conn:\n",
    "            self.connect()\n",
    "        \n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(sql)\n",
    "        \n",
    "        result = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        \n",
    "        return pd.DataFrame(result, columns=columns)\n",
    "    \n",
    "    def get_sample_for_analysis(self, table, size=100000, stratify_col=None):\n",
    "        \"\"\"\n",
    "        Get representative sample for statistical analysis\n",
    "        \"\"\"\n",
    "        if stratify_col:\n",
    "            # Stratified sampling\n",
    "            query = f\"\"\"\n",
    "            WITH strata AS (\n",
    "                SELECT \n",
    "                    {stratify_col},\n",
    "                    COUNT(*) as cnt,\n",
    "                    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER () as pct\n",
    "                FROM {table}\n",
    "                GROUP BY {stratify_col}\n",
    "            )\n",
    "            SELECT t.*\n",
    "            FROM {table} t\n",
    "            JOIN strata s ON t.{stratify_col} = s.{stratify_col}\n",
    "            WHERE RANDOM() < (s.pct / 100.0) * {size} / s.cnt\n",
    "            LIMIT {size}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # Simple random sampling\n",
    "            query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM {table}\n",
    "            ORDER BY RANDOM()\n",
    "            LIMIT {size}\n",
    "            \"\"\"\n",
    "        \n",
    "        return self.query(query)\n",
    "\n",
    "# Initialize (update with your credentials)\n",
    "REDSHIFT_HOST = os.getenv('REDSHIFT_HOST', 'your-cluster.redshift.amazonaws.com')\n",
    "REDSHIFT_PORT = os.getenv('REDSHIFT_PORT', '5439')\n",
    "REDSHIFT_DB = os.getenv('REDSHIFT_DB', 'marketing_db')\n",
    "REDSHIFT_USER = os.getenv('REDSHIFT_USER', input('Redshift username: '))\n",
    "REDSHIFT_PASSWORD = os.getenv('REDSHIFT_PASSWORD', getpass('Redshift password: '))\n",
    "\n",
    "rs_stats = RedshiftStatsAnalyzer(\n",
    "    REDSHIFT_HOST, REDSHIFT_PORT, REDSHIFT_DB,\n",
    "    REDSHIFT_USER, REDSHIFT_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Tests on Large Samples <a name=\"large-samples\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Everything is Significant\n",
    "\n",
    "With large samples (100k+), even tiny effects become statistically significant. We need to focus on **practical significance** (effect size) rather than just statistical significance (p-value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_large_sample_problem():\n",
    "    \"\"\"\n",
    "    Demonstrate how large samples make everything significant\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test with increasing sample sizes\n",
    "    for n in [100, 1000, 10000, 100000, 1000000]:\n",
    "        # Group A: mean = 100, std = 15\n",
    "        # Group B: mean = 100.5, std = 15 (tiny 0.5 difference!)\n",
    "        group_a = np.random.normal(100, 15, n)\n",
    "        group_b = np.random.normal(100.5, 15, n)\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = ttest_ind(group_a, group_b)\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        cohens_d = (group_b.mean() - group_a.mean()) / np.sqrt(\n",
    "            (group_a.std()**2 + group_b.std()**2) / 2\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'sample_size': n,\n",
    "            'mean_diff': group_b.mean() - group_a.mean(),\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'significant': p_value < 0.05\n",
    "        })\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"Impact of Sample Size on Statistical Significance\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_results.to_string(index=False))\n",
    "    print(\"\\nNote: Same tiny effect (0.5 difference), but significance\")\n",
    "    print(\"depends on sample size, not practical importance!\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# demonstrate_large_sample_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Effect Size + Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeSampleTesting:\n",
    "    \"\"\"\n",
    "    Statistical testing framework for large samples\n",
    "    Emphasizes effect size and practical significance\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def two_sample_test(group_a, group_b, metric_name=\"metric\", \n",
    "                        min_effect_size=0.02):\n",
    "        \"\"\"\n",
    "        Complete two-sample test with effect size analysis\n",
    "        \n",
    "        Args:\n",
    "            group_a, group_b: Arrays of values\n",
    "            metric_name: Name of metric being tested\n",
    "            min_effect_size: Minimum practical effect size (Cohen's d)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Basic statistics\n",
    "        n_a, n_b = len(group_a), len(group_b)\n",
    "        mean_a, mean_b = np.mean(group_a), np.mean(group_b)\n",
    "        std_a, std_b = np.std(group_a, ddof=1), np.std(group_b, ddof=1)\n",
    "        \n",
    "        # Statistical test\n",
    "        t_stat, p_value = ttest_ind(group_a, group_b)\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt((std_a**2 + std_b**2) / 2)\n",
    "        cohens_d = (mean_b - mean_a) / pooled_std\n",
    "        \n",
    "        # Confidence interval for mean difference\n",
    "        se_diff = np.sqrt(std_a**2/n_a + std_b**2/n_b)\n",
    "        ci_95 = stats.t.interval(\n",
    "            0.95, \n",
    "            n_a + n_b - 2,\n",
    "            loc=mean_b - mean_a,\n",
    "            scale=se_diff\n",
    "        )\n",
    "        \n",
    "        # Relative change\n",
    "        rel_change = (mean_b - mean_a) / mean_a * 100\n",
    "        \n",
    "        # Interpret effect size\n",
    "        if abs(cohens_d) < 0.2:\n",
    "            effect_interpretation = \"negligible\"\n",
    "        elif abs(cohens_d) < 0.5:\n",
    "            effect_interpretation = \"small\"\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            effect_interpretation = \"medium\"\n",
    "        else:\n",
    "            effect_interpretation = \"large\"\n",
    "        \n",
    "        # Practical significance\n",
    "        practically_significant = abs(cohens_d) >= min_effect_size\n",
    "        \n",
    "        results = {\n",
    "            'metric': metric_name,\n",
    "            'n_a': n_a,\n",
    "            'n_b': n_b,\n",
    "            'mean_a': mean_a,\n",
    "            'mean_b': mean_b,\n",
    "            'mean_diff': mean_b - mean_a,\n",
    "            'rel_change_pct': rel_change,\n",
    "            'ci_95_lower': ci_95[0],\n",
    "            'ci_95_upper': ci_95[1],\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'effect_interpretation': effect_interpretation,\n",
    "            'statistically_significant': p_value < 0.05,\n",
    "            'practically_significant': practically_significant\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_test_results(results):\n",
    "        \"\"\"Pretty print test results\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Two-Sample Test Results: {results['metric']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Sample sizes: A={results['n_a']:,}, B={results['n_b']:,}\")\n",
    "        print(f\"\\nMeans:\")\n",
    "        print(f\"  Group A: {results['mean_a']:.4f}\")\n",
    "        print(f\"  Group B: {results['mean_b']:.4f}\")\n",
    "        print(f\"  Difference: {results['mean_diff']:.4f} ({results['rel_change_pct']:.2f}%)\")\n",
    "        print(f\"  95% CI: [{results['ci_95_lower']:.4f}, {results['ci_95_upper']:.4f}]\")\n",
    "        print(f\"\\nStatistical Significance:\")\n",
    "        print(f\"  p-value: {results['p_value']:.6f}\")\n",
    "        print(f\"  Significant (α=0.05): {results['statistically_significant']}\")\n",
    "        print(f\"\\nEffect Size:\")\n",
    "        print(f\"  Cohen's d: {results['cohens_d']:.4f}\")\n",
    "        print(f\"  Interpretation: {results['effect_interpretation']}\")\n",
    "        print(f\"  Practically Significant: {results['practically_significant']}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def proportion_test(successes_a, n_a, successes_b, n_b, \n",
    "                       metric_name=\"conversion rate\"):\n",
    "        \"\"\"\n",
    "        Two-proportion z-test with effect size\n",
    "        Used for conversion rates, click-through rates, etc.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Proportions\n",
    "        p_a = successes_a / n_a\n",
    "        p_b = successes_b / n_b\n",
    "        \n",
    "        # Pooled proportion\n",
    "        p_pooled = (successes_a + successes_b) / (n_a + n_b)\n",
    "        \n",
    "        # Standard error\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_a + 1/n_b))\n",
    "        \n",
    "        # Z-statistic\n",
    "        z_stat = (p_b - p_a) / se\n",
    "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        # Effect size (h - Cohen's h for proportions)\n",
    "        cohens_h = 2 * (np.arcsin(np.sqrt(p_b)) - np.arcsin(np.sqrt(p_a)))\n",
    "        \n",
    "        # Confidence interval\n",
    "        se_diff = np.sqrt(p_a*(1-p_a)/n_a + p_b*(1-p_b)/n_b)\n",
    "        ci_95 = (\n",
    "            (p_b - p_a) - 1.96 * se_diff,\n",
    "            (p_b - p_a) + 1.96 * se_diff\n",
    "        )\n",
    "        \n",
    "        # Relative lift\n",
    "        relative_lift = (p_b - p_a) / p_a * 100\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'n_a': n_a,\n",
    "            'n_b': n_b,\n",
    "            'p_a': p_a,\n",
    "            'p_b': p_b,\n",
    "            'diff': p_b - p_a,\n",
    "            'relative_lift_pct': relative_lift,\n",
    "            'ci_95': ci_95,\n",
    "            'z_stat': z_stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_h': cohens_h,\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "# np.random.seed(42)\n",
    "# group_a = np.random.normal(100, 15, 100000)\n",
    "# group_b = np.random.normal(102, 15, 100000)  # 2% lift\n",
    "# \n",
    "# tester = LargeSampleTesting()\n",
    "# results = tester.two_sample_test(group_a, group_b, \"Revenue per User\", min_effect_size=0.1)\n",
    "# tester.print_test_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Massive Sample Sizes <a name=\"massive-samples\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_test_in_redshift(rs_conn, table, metric_col, group_col, \n",
    "                                  group_a_val, group_b_val):\n",
    "    \"\"\"\n",
    "    Perform statistical test directly in Redshift\n",
    "    Avoids loading millions of rows into memory\n",
    "    \"\"\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    WITH group_stats AS (\n",
    "        SELECT \n",
    "            {group_col} as group_name,\n",
    "            COUNT(*) as n,\n",
    "            AVG({metric_col}) as mean,\n",
    "            STDDEV({metric_col}) as std,\n",
    "            VARIANCE({metric_col}) as var\n",
    "        FROM {table}\n",
    "        WHERE {group_col} IN ('{group_a_val}', '{group_b_val}')\n",
    "            AND {metric_col} IS NOT NULL\n",
    "        GROUP BY {group_col}\n",
    "    ),\n",
    "    test_stats AS (\n",
    "        SELECT \n",
    "            MAX(CASE WHEN group_name = '{group_a_val}' THEN n END) as n_a,\n",
    "            MAX(CASE WHEN group_name = '{group_b_val}' THEN n END) as n_b,\n",
    "            MAX(CASE WHEN group_name = '{group_a_val}' THEN mean END) as mean_a,\n",
    "            MAX(CASE WHEN group_name = '{group_b_val}' THEN mean END) as mean_b,\n",
    "            MAX(CASE WHEN group_name = '{group_a_val}' THEN std END) as std_a,\n",
    "            MAX(CASE WHEN group_name = '{group_b_val}' THEN std END) as std_b\n",
    "        FROM group_stats\n",
    "    )\n",
    "    SELECT \n",
    "        n_a,\n",
    "        n_b,\n",
    "        mean_a,\n",
    "        mean_b,\n",
    "        std_a,\n",
    "        std_b,\n",
    "        mean_b - mean_a as mean_diff,\n",
    "        (mean_b - mean_a) / mean_a * 100 as rel_change_pct,\n",
    "        -- T-statistic\n",
    "        (mean_b - mean_a) / SQRT((std_a*std_a/n_a) + (std_b*std_b/n_b)) as t_stat,\n",
    "        -- Cohen's d\n",
    "        (mean_b - mean_a) / SQRT((std_a*std_a + std_b*std_b) / 2) as cohens_d\n",
    "    FROM test_stats\n",
    "    \"\"\"\n",
    "    \n",
    "    result = rs_conn.query(query)\n",
    "    \n",
    "    # Calculate p-value in Python (Redshift doesn't have t-distribution)\n",
    "    if not result.empty:\n",
    "        t_stat = result['t_stat'].iloc[0]\n",
    "        df = result['n_a'].iloc[0] + result['n_b'].iloc[0] - 2\n",
    "        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n",
    "        result['p_value'] = p_value\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "# results = statistical_test_in_redshift(\n",
    "#     rs_stats, \n",
    "#     'marketing_events', \n",
    "#     'revenue', \n",
    "#     'channel', \n",
    "#     'google', \n",
    "#     'facebook'\n",
    "# )\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bootstrap and Resampling at Scale <a name=\"bootstrap\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalableBootstrap:\n",
    "    \"\"\"\n",
    "    Bootstrap methods optimized for large datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def bootstrap_ci(data, statistic_func, n_bootstrap=1000, ci=0.95, \n",
    "                     subsample_size=None):\n",
    "        \"\"\"\n",
    "        Calculate bootstrap confidence interval\n",
    "        \n",
    "        Args:\n",
    "            data: Array of data\n",
    "            statistic_func: Function to calculate statistic (e.g., np.mean)\n",
    "            n_bootstrap: Number of bootstrap samples\n",
    "            ci: Confidence level\n",
    "            subsample_size: If set, use subsampling for efficiency\n",
    "        \"\"\"\n",
    "        \n",
    "        bootstrap_stats = []\n",
    "        \n",
    "        # Use subsampling for very large datasets\n",
    "        sample_size = subsample_size if subsample_size else len(data)\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            # Bootstrap sample\n",
    "            sample = resample(data, n_samples=sample_size, replace=True)\n",
    "            # Calculate statistic\n",
    "            stat = statistic_func(sample)\n",
    "            bootstrap_stats.append(stat)\n",
    "        \n",
    "        # Calculate confidence interval\n",
    "        alpha = 1 - ci\n",
    "        lower_percentile = (alpha / 2) * 100\n",
    "        upper_percentile = (1 - alpha / 2) * 100\n",
    "        \n",
    "        ci_lower = np.percentile(bootstrap_stats, lower_percentile)\n",
    "        ci_upper = np.percentile(bootstrap_stats, upper_percentile)\n",
    "        \n",
    "        return {\n",
    "            'estimate': statistic_func(data),\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'ci_level': ci,\n",
    "            'bootstrap_distribution': bootstrap_stats\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def bootstrap_hypothesis_test(group_a, group_b, statistic_func=np.mean,\n",
    "                                   n_bootstrap=10000, subsample_size=10000):\n",
    "        \"\"\"\n",
    "        Bootstrap hypothesis test for difference between groups\n",
    "        \n",
    "        H0: No difference between groups\n",
    "        \"\"\"\n",
    "        \n",
    "        # Observed difference\n",
    "        obs_diff = statistic_func(group_b) - statistic_func(group_a)\n",
    "        \n",
    "        # Subsample if datasets are too large\n",
    "        if subsample_size and len(group_a) > subsample_size:\n",
    "            group_a = np.random.choice(group_a, subsample_size, replace=False)\n",
    "            group_b = np.random.choice(group_b, subsample_size, replace=False)\n",
    "        \n",
    "        # Pool data under null hypothesis\n",
    "        pooled = np.concatenate([group_a, group_b])\n",
    "        n_a = len(group_a)\n",
    "        n_b = len(group_b)\n",
    "        \n",
    "        # Bootstrap null distribution\n",
    "        null_diffs = []\n",
    "        for i in range(n_bootstrap):\n",
    "            # Shuffle and split\n",
    "            shuffled = resample(pooled, n_samples=len(pooled), replace=False)\n",
    "            boot_a = shuffled[:n_a]\n",
    "            boot_b = shuffled[n_a:]\n",
    "            \n",
    "            # Calculate difference\n",
    "            diff = statistic_func(boot_b) - statistic_func(boot_a)\n",
    "            null_diffs.append(diff)\n",
    "        \n",
    "        # Calculate p-value\n",
    "        p_value = np.mean(np.abs(null_diffs) >= np.abs(obs_diff))\n",
    "        \n",
    "        return {\n",
    "            'observed_diff': obs_diff,\n",
    "            'p_value': p_value,\n",
    "            'null_distribution': null_diffs\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize_bootstrap_results(results, title=\"Bootstrap Results\"):\n",
    "        \"\"\"\n",
    "        Visualize bootstrap distribution and confidence interval\n",
    "        \"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Bootstrap distribution\n",
    "        ax1.hist(results['bootstrap_distribution'], bins=50, \n",
    "                edgecolor='black', alpha=0.7)\n",
    "        ax1.axvline(results['estimate'], color='red', linestyle='--', \n",
    "                   linewidth=2, label='Estimate')\n",
    "        ax1.axvline(results['ci_lower'], color='green', linestyle='--', \n",
    "                   linewidth=2, label=f'{results[\"ci_level\"]*100}% CI')\n",
    "        ax1.axvline(results['ci_upper'], color='green', linestyle='--', \n",
    "                   linewidth=2)\n",
    "        ax1.set_xlabel('Statistic Value')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Bootstrap Distribution')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Box plot\n",
    "        ax2.boxplot(results['bootstrap_distribution'], vert=True)\n",
    "        ax2.set_ylabel('Statistic Value')\n",
    "        ax2.set_title('Bootstrap Distribution (Box Plot)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "# np.random.seed(42)\n",
    "# data = np.random.lognormal(3, 1, 100000)  # Large skewed dataset\n",
    "# \n",
    "# bs = ScalableBootstrap()\n",
    "# results = bs.bootstrap_ci(data, np.median, n_bootstrap=1000, subsample_size=10000)\n",
    "# print(f\"Median: {results['estimate']:.2f}\")\n",
    "# print(f\"95% CI: [{results['ci_lower']:.2f}, {results['ci_upper']:.2f}]\")\n",
    "# bs.visualize_bootstrap_results(results, \"Bootstrap CI for Median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Power Analysis for Large Experiments <a name=\"power-analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerAnalyzer:\n",
    "    \"\"\"\n",
    "    Power analysis for A/B tests and experiments\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_required_sample_size(baseline_rate, mde, alpha=0.05, power=0.80):\n",
    "        \"\"\"\n",
    "        Calculate required sample size for proportion test\n",
    "        \n",
    "        Args:\n",
    "            baseline_rate: Current conversion rate (e.g., 0.03)\n",
    "            mde: Minimum detectable effect (relative, e.g., 0.05 for 5% lift)\n",
    "            alpha: Significance level\n",
    "            power: Statistical power (1 - beta)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Target rate\n",
    "        target_rate = baseline_rate * (1 + mde)\n",
    "        \n",
    "        # Effect size\n",
    "        effect_size = proportion_effectsize(baseline_rate, target_rate)\n",
    "        \n",
    "        # Calculate sample size\n",
    "        analysis = TTestIndPower()\n",
    "        n_per_group = analysis.solve_power(\n",
    "            effect_size=effect_size,\n",
    "            alpha=alpha,\n",
    "            power=power,\n",
    "            ratio=1.0,\n",
    "            alternative='two-sided'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'n_per_group': int(np.ceil(n_per_group)),\n",
    "            'total_sample_size': int(np.ceil(n_per_group * 2)),\n",
    "            'baseline_rate': baseline_rate,\n",
    "            'target_rate': target_rate,\n",
    "            'mde': mde,\n",
    "            'effect_size': effect_size,\n",
    "            'alpha': alpha,\n",
    "            'power': power\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def power_curve(baseline_rate, sample_size_per_group, alpha=0.05):\n",
    "        \"\"\"\n",
    "        Generate power curve showing detectable effect vs power\n",
    "        \"\"\"\n",
    "        \n",
    "        # Range of relative effects to test\n",
    "        relative_effects = np.linspace(0.01, 0.20, 50)\n",
    "        \n",
    "        powers = []\n",
    "        for rel_effect in relative_effects:\n",
    "            target_rate = baseline_rate * (1 + rel_effect)\n",
    "            effect_size = proportion_effectsize(baseline_rate, target_rate)\n",
    "            \n",
    "            analysis = TTestIndPower()\n",
    "            power = analysis.solve_power(\n",
    "                effect_size=effect_size,\n",
    "                nobs1=sample_size_per_group,\n",
    "                alpha=alpha,\n",
    "                ratio=1.0,\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            powers.append(power)\n",
    "        \n",
    "        # Plot\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=relative_effects * 100,\n",
    "            y=powers,\n",
    "            mode='lines',\n",
    "            name='Power',\n",
    "            line=dict(color='blue', width=2)\n",
    "        ))\n",
    "        \n",
    "        # Add 80% power line\n",
    "        fig.add_hline(y=0.80, line_dash=\"dash\", line_color=\"red\",\n",
    "                     annotation_text=\"80% Power\")\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Power Curve (n={sample_size_per_group:,} per group)',\n",
    "            xaxis_title='Relative Effect (%)',\n",
    "            yaxis_title='Statistical Power',\n",
    "            yaxis=dict(range=[0, 1]),\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'relative_effect_pct': relative_effects * 100,\n",
    "            'power': powers\n",
    "        })\n",
    "    \n",
    "    @staticmethod\n",
    "    def runtime_calculator(daily_traffic, n_required):\n",
    "        \"\"\"\n",
    "        Calculate how long experiment needs to run\n",
    "        \"\"\"\n",
    "        \n",
    "        # Per group\n",
    "        daily_per_group = daily_traffic / 2\n",
    "        days_required = np.ceil(n_required / daily_per_group)\n",
    "        \n",
    "        return {\n",
    "            'days_required': int(days_required),\n",
    "            'weeks_required': days_required / 7,\n",
    "            'daily_traffic': daily_traffic,\n",
    "            'daily_per_group': daily_per_group,\n",
    "            'total_required': n_required * 2\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def sequential_testing_boundaries(n_max, alpha=0.05, n_looks=5):\n",
    "        \"\"\"\n",
    "        Calculate adjusted significance levels for sequential testing\n",
    "        Using O'Brien-Fleming spending function\n",
    "        \"\"\"\n",
    "        \n",
    "        # Information fractions\n",
    "        info_fractions = np.linspace(0.2, 1.0, n_looks)\n",
    "        \n",
    "        # O'Brien-Fleming boundaries\n",
    "        boundaries = []\n",
    "        for fraction in info_fractions:\n",
    "            z_boundary = stats.norm.ppf(1 - alpha/2) / np.sqrt(fraction)\n",
    "            p_boundary = 2 * (1 - stats.norm.cdf(z_boundary))\n",
    "            boundaries.append(p_boundary)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'look_number': range(1, n_looks + 1),\n",
    "            'sample_size': (info_fractions * n_max).astype(int),\n",
    "            'info_fraction': info_fractions,\n",
    "            'p_value_boundary': boundaries\n",
    "        })\n",
    "\n",
    "# Example usage\n",
    "# pa = PowerAnalyzer()\n",
    "# \n",
    "# # Calculate required sample size\n",
    "# result = pa.calculate_required_sample_size(\n",
    "#     baseline_rate=0.03,  # 3% conversion rate\n",
    "#     mde=0.10,  # Want to detect 10% lift\n",
    "#     power=0.80\n",
    "# )\n",
    "# print(f\"Required sample size per group: {result['n_per_group']:,}\")\n",
    "# print(f\"Total sample size: {result['total_sample_size']:,}\")\n",
    "# \n",
    "# # Calculate runtime\n",
    "# runtime = pa.runtime_calculator(daily_traffic=50000, n_required=result['n_per_group'])\n",
    "# print(f\"Days required: {runtime['days_required']}\")\n",
    "# print(f\"Weeks required: {runtime['weeks_required']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bayesian Statistics for Marketing <a name=\"bayesian\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianMarketingAnalysis:\n",
    "    \"\"\"\n",
    "    Bayesian methods for marketing analytics\n",
    "    Better for continuous monitoring and incorporating prior knowledge\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def bayesian_ab_test(conversions_a, visitors_a, conversions_b, visitors_b,\n",
    "                         prior_alpha=1, prior_beta=1, n_samples=10000):\n",
    "        \"\"\"\n",
    "        Bayesian A/B test for conversion rates\n",
    "        Uses Beta-Binomial conjugate prior\n",
    "        \"\"\"\n",
    "        \n",
    "        # Posterior distributions\n",
    "        posterior_a = beta(prior_alpha + conversions_a, \n",
    "                          prior_beta + visitors_a - conversions_a)\n",
    "        posterior_b = beta(prior_alpha + conversions_b, \n",
    "                          prior_beta + visitors_b - conversions_b)\n",
    "        \n",
    "        # Sample from posteriors\n",
    "        samples_a = posterior_a.rvs(n_samples)\n",
    "        samples_b = posterior_b.rvs(n_samples)\n",
    "        \n",
    "        # Probability B > A\n",
    "        prob_b_better = np.mean(samples_b > samples_a)\n",
    "        \n",
    "        # Expected lift\n",
    "        lift_samples = (samples_b - samples_a) / samples_a\n",
    "        expected_lift = np.mean(lift_samples)\n",
    "        lift_ci = np.percentile(lift_samples, [2.5, 97.5])\n",
    "        \n",
    "        # Expected loss (risk of choosing wrong variant)\n",
    "        loss_a = np.mean(np.maximum(samples_b - samples_a, 0))\n",
    "        loss_b = np.mean(np.maximum(samples_a - samples_b, 0))\n",
    "        \n",
    "        return {\n",
    "            'prob_b_better': prob_b_better,\n",
    "            'prob_a_better': 1 - prob_b_better,\n",
    "            'expected_lift': expected_lift,\n",
    "            'lift_ci_95': lift_ci,\n",
    "            'expected_loss_a': loss_a,\n",
    "            'expected_loss_b': loss_b,\n",
    "            'samples_a': samples_a,\n",
    "            'samples_b': samples_b,\n",
    "            'posterior_a_mean': posterior_a.mean(),\n",
    "            'posterior_b_mean': posterior_b.mean()\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize_bayesian_test(results):\n",
    "        \"\"\"\n",
    "        Visualize Bayesian A/B test results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Posterior distributions\n",
    "        axes[0, 0].hist(results['samples_a'], bins=50, alpha=0.5, \n",
    "                       label='Variant A', density=True)\n",
    "        axes[0, 0].hist(results['samples_b'], bins=50, alpha=0.5, \n",
    "                       label='Variant B', density=True)\n",
    "        axes[0, 0].set_xlabel('Conversion Rate')\n",
    "        axes[0, 0].set_ylabel('Density')\n",
    "        axes[0, 0].set_title('Posterior Distributions')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # 2. Lift distribution\n",
    "        lift = (results['samples_b'] - results['samples_a']) / results['samples_a'] * 100\n",
    "        axes[0, 1].hist(lift, bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[0, 1].axvline(np.percentile(lift, 2.5), color='green', \n",
    "                          linestyle='--', label='95% CI')\n",
    "        axes[0, 1].axvline(np.percentile(lift, 97.5), color='green', \n",
    "                          linestyle='--')\n",
    "        axes[0, 1].set_xlabel('Lift (%)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('Distribution of Lift')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # 3. Probability B beats A\n",
    "        categories = ['A Better', 'B Better']\n",
    "        probs = [results['prob_a_better'], results['prob_b_better']]\n",
    "        colors = ['#ff6b6b' if p < 0.5 else '#51cf66' for p in probs]\n",
    "        axes[1, 0].bar(categories, probs, color=colors, edgecolor='black')\n",
    "        axes[1, 0].set_ylabel('Probability')\n",
    "        axes[1, 0].set_title('Probability of Being Better')\n",
    "        axes[1, 0].set_ylim([0, 1])\n",
    "        for i, v in enumerate(probs):\n",
    "            axes[1, 0].text(i, v + 0.02, f'{v:.1%}', \n",
    "                           ha='center', fontweight='bold')\n",
    "        \n",
    "        # 4. Expected loss\n",
    "        losses = [results['expected_loss_a'], results['expected_loss_b']]\n",
    "        axes[1, 1].bar(['Choose A', 'Choose B'], losses, \n",
    "                      color=['#ff6b6b', '#51cf66'], edgecolor='black')\n",
    "        axes[1, 1].set_ylabel('Expected Loss')\n",
    "        axes[1, 1].set_title('Expected Loss (Risk)')\n",
    "        for i, v in enumerate(losses):\n",
    "            axes[1, 1].text(i, v + max(losses)*0.02, f'{v:.4f}', \n",
    "                           ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def bayesian_revenue_test(revenue_a, revenue_b, n_samples=10000):\n",
    "        \"\"\"\n",
    "        Bayesian test for revenue (continuous metric)\n",
    "        Uses PyMC3 for more complex modeling\n",
    "        \"\"\"\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            # Priors\n",
    "            mu_a = pm.Normal('mu_a', mu=np.mean(revenue_a), sd=np.std(revenue_a))\n",
    "            mu_b = pm.Normal('mu_b', mu=np.mean(revenue_b), sd=np.std(revenue_b))\n",
    "            \n",
    "            sigma_a = pm.HalfNormal('sigma_a', sd=np.std(revenue_a))\n",
    "            sigma_b = pm.HalfNormal('sigma_b', sd=np.std(revenue_b))\n",
    "            \n",
    "            # Likelihood\n",
    "            obs_a = pm.Normal('obs_a', mu=mu_a, sd=sigma_a, observed=revenue_a)\n",
    "            obs_b = pm.Normal('obs_b', mu=mu_b, sd=sigma_b, observed=revenue_b)\n",
    "            \n",
    "            # Difference\n",
    "            diff = pm.Deterministic('diff', mu_b - mu_a)\n",
    "            lift = pm.Deterministic('lift', (mu_b - mu_a) / mu_a)\n",
    "            \n",
    "            # Sample\n",
    "            trace = pm.sample(n_samples, return_inferencedata=True, \n",
    "                            progressbar=False)\n",
    "        \n",
    "        # Extract results\n",
    "        diff_samples = trace.posterior['diff'].values.flatten()\n",
    "        lift_samples = trace.posterior['lift'].values.flatten()\n",
    "        \n",
    "        return {\n",
    "            'prob_b_better': np.mean(diff_samples > 0),\n",
    "            'expected_diff': np.mean(diff_samples),\n",
    "            'diff_ci_95': np.percentile(diff_samples, [2.5, 97.5]),\n",
    "            'expected_lift': np.mean(lift_samples),\n",
    "            'lift_ci_95': np.percentile(lift_samples, [2.5, 97.5]),\n",
    "            'trace': trace\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "# bayes = BayesianMarketingAnalysis()\n",
    "# \n",
    "# # Simulate A/B test data\n",
    "# conversions_a, visitors_a = 250, 10000\n",
    "# conversions_b, visitors_b = 275, 10000\n",
    "# \n",
    "# results = bayes.bayesian_ab_test(conversions_a, visitors_a, \n",
    "#                                  conversions_b, visitors_b)\n",
    "# \n",
    "# print(f\"Probability B is better: {results['prob_b_better']:.1%}\")\n",
    "# print(f\"Expected lift: {results['expected_lift']:.2%}\")\n",
    "# print(f\"95% CI: [{results['lift_ci_95'][0]:.2%}, {results['lift_ci_95'][1]:.2%}]\")\n",
    "# \n",
    "# bayes.visualize_bayesian_test(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Series Analysis at Scale <a name=\"timeseries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesAnalyzer:\n",
    "    \"\"\"\n",
    "    Time series analysis for marketing metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def decompose_series(df, date_col, value_col, freq=7):\n",
    "        \"\"\"\n",
    "        Decompose time series into trend, seasonal, and residual\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with time series data\n",
    "            date_col: Date column name\n",
    "            value_col: Value column name\n",
    "            freq: Seasonal frequency (7 for weekly, 30 for monthly)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure sorted by date\n",
    "        df_sorted = df.sort_values(date_col)\n",
    "        \n",
    "        # Decomposition\n",
    "        decomposition = seasonal_decompose(\n",
    "            df_sorted[value_col],\n",
    "            model='additive',\n",
    "            period=freq\n",
    "        )\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "        \n",
    "        # Original\n",
    "        axes[0].plot(df_sorted[date_col], df_sorted[value_col])\n",
    "        axes[0].set_ylabel('Original')\n",
    "        axes[0].set_title('Time Series Decomposition')\n",
    "        \n",
    "        # Trend\n",
    "        axes[1].plot(df_sorted[date_col], decomposition.trend)\n",
    "        axes[1].set_ylabel('Trend')\n",
    "        \n",
    "        # Seasonal\n",
    "        axes[2].plot(df_sorted[date_col], decomposition.seasonal)\n",
    "        axes[2].set_ylabel('Seasonal')\n",
    "        \n",
    "        # Residual\n",
    "        axes[3].plot(df_sorted[date_col], decomposition.resid)\n",
    "        axes[3].set_ylabel('Residual')\n",
    "        axes[3].set_xlabel('Date')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return decomposition\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_anomalies(df, date_col, value_col, threshold=3):\n",
    "        \"\"\"\n",
    "        Detect anomalies using statistical methods\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        df = df.copy()\n",
    "        df['rolling_mean'] = df[value_col].rolling(window=7, center=True).mean()\n",
    "        df['rolling_std'] = df[value_col].rolling(window=7, center=True).std()\n",
    "        \n",
    "        # Z-score\n",
    "        df['z_score'] = (df[value_col] - df['rolling_mean']) / df['rolling_std']\n",
    "        \n",
    "        # Flag anomalies\n",
    "        df['is_anomaly'] = abs(df['z_score']) > threshold\n",
    "        \n",
    "        # Visualize\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Normal points\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[~df['is_anomaly']][date_col],\n",
    "            y=df[~df['is_anomaly']][value_col],\n",
    "            mode='lines+markers',\n",
    "            name='Normal',\n",
    "            line=dict(color='blue')\n",
    "        ))\n",
    "        \n",
    "        # Anomalies\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[df['is_anomaly']][date_col],\n",
    "            y=df[df['is_anomaly']][value_col],\n",
    "            mode='markers',\n",
    "            name='Anomaly',\n",
    "            marker=dict(color='red', size=10, symbol='x')\n",
    "        ))\n",
    "        \n",
    "        # Confidence bands\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[date_col],\n",
    "            y=df['rolling_mean'] + threshold * df['rolling_std'],\n",
    "            mode='lines',\n",
    "            name='Upper bound',\n",
    "            line=dict(color='gray', dash='dash')\n",
    "        ))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[date_col],\n",
    "            y=df['rolling_mean'] - threshold * df['rolling_std'],\n",
    "            mode='lines',\n",
    "            name='Lower bound',\n",
    "            line=dict(color='gray', dash='dash')\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Anomaly Detection',\n",
    "            xaxis_title='Date',\n",
    "            yaxis_title='Value',\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        return df[df['is_anomaly']]\n",
    "    \n",
    "    @staticmethod\n",
    "    def forecast_with_prophet(df, date_col, value_col, periods=30):\n",
    "        \"\"\"\n",
    "        Forecast using Facebook Prophet\n",
    "        Good for marketing data with trends and seasonality\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare data for Prophet\n",
    "        df_prophet = df[[date_col, value_col]].copy()\n",
    "        df_prophet.columns = ['ds', 'y']\n",
    "        \n",
    "        # Fit model\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False\n",
    "        )\n",
    "        model.fit(df_prophet)\n",
    "        \n",
    "        # Make future dataframe\n",
    "        future = model.make_future_dataframe(periods=periods)\n",
    "        \n",
    "        # Predict\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Plot\n",
    "        fig = model.plot(forecast)\n",
    "        plt.title(f'{value_col} Forecast')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot components\n",
    "        fig = model.plot_components(forecast)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return forecast\n",
    "\n",
    "# Example usage\n",
    "# # Generate sample time series\n",
    "# dates = pd.date_range('2023-01-01', periods=365, freq='D')\n",
    "# trend = np.linspace(100, 150, 365)\n",
    "# seasonal = 10 * np.sin(2 * np.pi * np.arange(365) / 7)\n",
    "# noise = np.random.normal(0, 5, 365)\n",
    "# values = trend + seasonal + noise\n",
    "# \n",
    "# df_ts = pd.DataFrame({'date': dates, 'revenue': values})\n",
    "# \n",
    "# tsa = TimeSeriesAnalyzer()\n",
    "# decomp = tsa.decompose_series(df_ts, 'date', 'revenue', freq=7)\n",
    "# anomalies = tsa.detect_anomalies(df_ts, 'date', 'revenue', threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Project: 50M Conversion Analysis <a name=\"project\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PROJECT: Statistical Analysis of 50M Conversions\n",
    "\n",
    "Scenario:\n",
    "You have a Redshift table with 50M conversion events from the past year.\n",
    "Perform comprehensive statistical analysis to answer:\n",
    "\n",
    "1. Which channels have significantly different conversion rates?\n",
    "2. What is the confidence interval for revenue per conversion?\n",
    "3. Are there seasonal patterns in conversion rates?\n",
    "4. Which variants in ongoing A/B tests should we choose?\n",
    "5. Can we forecast next month's conversions?\n",
    "\n",
    "Requirements:\n",
    "- All analysis must handle 50M+ rows efficiently\n",
    "- Use appropriate statistical tests\n",
    "- Calculate effect sizes and confidence intervals\n",
    "- Create visualizations\n",
    "- Provide actionable recommendations\n",
    "\"\"\"\n",
    "\n",
    "class ConversionAnalysisProject:\n",
    "    \"\"\"\n",
    "    Complete statistical analysis framework for large conversion dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rs_conn, table_name):\n",
    "        self.rs_conn = rs_conn\n",
    "        self.table = table_name\n",
    "        self.results = {}\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Execute full analysis pipeline\"\"\"\n",
    "        print(\"Starting 50M Conversion Analysis...\\n\")\n",
    "        \n",
    "        # 1. Channel comparison\n",
    "        print(\"[1/5] Analyzing channel differences...\")\n",
    "        self.results['channels'] = self.analyze_channels()\n",
    "        \n",
    "        # 2. Revenue analysis\n",
    "        print(\"[2/5] Analyzing revenue distribution...\")\n",
    "        self.results['revenue'] = self.analyze_revenue()\n",
    "        \n",
    "        # 3. Time series analysis\n",
    "        print(\"[3/5] Analyzing temporal patterns...\")\n",
    "        self.results['timeseries'] = self.analyze_timeseries()\n",
    "        \n",
    "        # 4. A/B test analysis\n",
    "        print(\"[4/5] Analyzing A/B tests...\")\n",
    "        self.results['ab_tests'] = self.analyze_ab_tests()\n",
    "        \n",
    "        # 5. Forecasting\n",
    "        print(\"[5/5] Generating forecasts...\")\n",
    "        self.results['forecast'] = self.generate_forecast()\n",
    "        \n",
    "        print(\"\\n✓ Analysis complete!\")\n",
    "        return self.results\n",
    "    \n",
    "    def analyze_channels(self):\n",
    "        \"\"\"\n",
    "        Compare conversion rates across channels\n",
    "        \"\"\"\n",
    "        # Get channel statistics from Redshift\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            channel,\n",
    "            COUNT(*) as total_events,\n",
    "            SUM(CASE WHEN converted = 1 THEN 1 ELSE 0 END) as conversions,\n",
    "            AVG(CASE WHEN converted = 1 THEN 1.0 ELSE 0.0 END) as conversion_rate,\n",
    "            STDDEV(CASE WHEN converted = 1 THEN 1.0 ELSE 0.0 END) as std_dev\n",
    "        FROM {self.table}\n",
    "        GROUP BY channel\n",
    "        ORDER BY total_events DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.rs_conn.query(query)\n",
    "        \n",
    "        # Pairwise comparisons\n",
    "        tester = LargeSampleTesting()\n",
    "        comparisons = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            for j in range(i+1, len(df)):\n",
    "                channel_a = df.iloc[i]\n",
    "                channel_b = df.iloc[j]\n",
    "                \n",
    "                result = tester.proportion_test(\n",
    "                    channel_a['conversions'], channel_a['total_events'],\n",
    "                    channel_b['conversions'], channel_b['total_events'],\n",
    "                    f\"{channel_a['channel']} vs {channel_b['channel']}\"\n",
    "                )\n",
    "                comparisons.append(result)\n",
    "        \n",
    "        return {\n",
    "            'channel_stats': df,\n",
    "            'comparisons': comparisons\n",
    "        }\n",
    "    \n",
    "    def analyze_revenue(self):\n",
    "        \"\"\"\n",
    "        Analyze revenue distribution with bootstrap CI\n",
    "        \"\"\"\n",
    "        # Sample revenue data (can't load 50M into memory)\n",
    "        query = f\"\"\"\n",
    "        SELECT revenue\n",
    "        FROM {self.table}\n",
    "        WHERE converted = 1\n",
    "            AND revenue > 0\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 100000\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.rs_conn.query(query)\n",
    "        revenue_data = df['revenue'].values\n",
    "        \n",
    "        # Bootstrap CI for median\n",
    "        bs = ScalableBootstrap()\n",
    "        ci_result = bs.bootstrap_ci(\n",
    "            revenue_data,\n",
    "            np.median,\n",
    "            n_bootstrap=1000\n",
    "        )\n",
    "        \n",
    "        return ci_result\n",
    "    \n",
    "    def analyze_timeseries(self):\n",
    "        \"\"\"\n",
    "        Analyze temporal patterns\n",
    "        \"\"\"\n",
    "        # Get daily conversion rates\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            DATE(timestamp) as date,\n",
    "            COUNT(*) as total,\n",
    "            SUM(CASE WHEN converted = 1 THEN 1 ELSE 0 END) as conversions,\n",
    "            AVG(CASE WHEN converted = 1 THEN 1.0 ELSE 0.0 END) as conversion_rate\n",
    "        FROM {self.table}\n",
    "        GROUP BY DATE(timestamp)\n",
    "        ORDER BY date\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.rs_conn.query(query)\n",
    "        \n",
    "        # Decompose\n",
    "        tsa = TimeSeriesAnalyzer()\n",
    "        decomp = tsa.decompose_series(df, 'date', 'conversion_rate', freq=7)\n",
    "        \n",
    "        return {\n",
    "            'daily_data': df,\n",
    "            'decomposition': decomp\n",
    "        }\n",
    "    \n",
    "    def analyze_ab_tests(self):\n",
    "        \"\"\"\n",
    "        Analyze active A/B tests\n",
    "        \"\"\"\n",
    "        # Assume we have variant column\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            variant,\n",
    "            COUNT(*) as visitors,\n",
    "            SUM(CASE WHEN converted = 1 THEN 1 ELSE 0 END) as conversions\n",
    "        FROM {self.table}\n",
    "        WHERE variant IS NOT NULL\n",
    "        GROUP BY variant\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.rs_conn.query(query)\n",
    "        \n",
    "        if len(df) >= 2:\n",
    "            # Bayesian analysis\n",
    "            bayes = BayesianMarketingAnalysis()\n",
    "            result = bayes.bayesian_ab_test(\n",
    "                df.iloc[0]['conversions'], df.iloc[0]['visitors'],\n",
    "                df.iloc[1]['conversions'], df.iloc[1]['visitors']\n",
    "            )\n",
    "            return result\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def generate_forecast(self):\n",
    "        \"\"\"\n",
    "        Forecast next 30 days of conversions\n",
    "        \"\"\"\n",
    "        # Get historical daily conversions\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            DATE(timestamp) as date,\n",
    "            SUM(CASE WHEN converted = 1 THEN 1 ELSE 0 END) as conversions\n",
    "        FROM {self.table}\n",
    "        GROUP BY DATE(timestamp)\n",
    "        ORDER BY date\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.rs_conn.query(query)\n",
    "        \n",
    "        # Forecast with Prophet\n",
    "        tsa = TimeSeriesAnalyzer()\n",
    "        forecast = tsa.forecast_with_prophet(df, 'date', 'conversions', periods=30)\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        Generate executive report\n",
    "        \"\"\"\n",
    "        # Implementation left as exercise for students\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "# project = ConversionAnalysisProject(rs_stats, 'conversion_events')\n",
    "# results = project.run_complete_analysis()\n",
    "# report = project.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercises <a name=\"exercises\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Channel Performance Analysis\n",
    "\n",
    "**Task:** Using a large marketing dataset:\n",
    "1. Compare conversion rates across all channels\n",
    "2. Calculate effect sizes for all pairwise comparisons\n",
    "3. Adjust for multiple comparisons (Bonferroni correction)\n",
    "4. Visualize results\n",
    "5. Provide recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Sample Size Planning\n",
    "\n",
    "**Task:** Plan an A/B test:\n",
    "1. Current conversion rate: 2.5%\n",
    "2. Want to detect 5% relative lift\n",
    "3. Calculate required sample size\n",
    "4. Given 100k daily visitors, how long to run?\n",
    "5. Create power curve\n",
    "6. Set up sequential testing boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Bayesian vs Frequentist Comparison\n",
    "\n",
    "**Task:** Analyze the same A/B test both ways:\n",
    "1. Perform frequentist test (t-test)\n",
    "2. Perform Bayesian test\n",
    "3. Compare conclusions\n",
    "4. Discuss pros/cons of each approach\n",
    "5. When would you use each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Time Series Anomaly Detection\n",
    "\n",
    "**Task:** Build anomaly detection system:\n",
    "1. Load daily revenue data\n",
    "2. Implement multiple anomaly detection methods\n",
    "3. Compare methods\n",
    "4. Create automated alerting logic\n",
    "5. Test on historical data with known anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Large Sample Testing**\n",
    "   - Why p-values aren't enough\n",
    "   - Importance of effect sizes\n",
    "   - Practical vs statistical significance\n",
    "\n",
    "2. **Efficient Analysis Methods**\n",
    "   - In-database statistical tests\n",
    "   - Smart sampling strategies\n",
    "   - Bootstrap at scale\n",
    "\n",
    "3. **Experimental Design**\n",
    "   - Power analysis\n",
    "   - Sample size calculation\n",
    "   - Sequential testing\n",
    "\n",
    "4. **Bayesian Methods**\n",
    "   - Bayesian A/B testing\n",
    "   - Continuous monitoring\n",
    "   - Incorporating priors\n",
    "\n",
    "5. **Time Series Analysis**\n",
    "   - Decomposition\n",
    "   - Anomaly detection\n",
    "   - Forecasting\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Week 8: Advanced A/B Testing Platform\n",
    "- Practice with real datasets\n",
    "- Build automated analysis pipelines\n",
    "- Implement production systems\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Evan Miller's A/B Tools](https://www.evanmiller.org/ab-testing/)\n",
    "- [Trustworthy Online Controlled Experiments](https://www.amazon.com/Trustworthy-Online-Controlled-Experiments-Practical/dp/1108724264)\n",
    "- [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)\n",
    "- [Prophet Documentation](https://facebook.github.io/prophet/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
