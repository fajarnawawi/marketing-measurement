{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Advanced Marketing Mix Modeling in Production\n",
    "\n",
    "## Learning Objectives\n",
    "- Build production-scale Marketing Mix Models (MMM)\n",
    "- Implement Bayesian MMM with PyMC3\n",
    "- Design hierarchical models for geo/segment MMM\n",
    "- Automate model selection and validation\n",
    "- Build budget optimization systems with constraints\n",
    "- Implement forecasting at scale\n",
    "- Deploy enterprise MMM platforms\n",
    "- Handle adstock and saturation effects\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install pandas numpy scipy statsmodels\n",
    "pip install pymc3 arviz theano\n",
    "pip install scikit-learn xgboost lightgbm\n",
    "pip install plotly seaborn matplotlib\n",
    "pip install cvxpy scipy.optimize\n",
    "pip install psycopg2-binary sqlalchemy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import gc\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statistics and modeling\n",
    "from scipy import stats, optimize\n",
    "from scipy.special import expit\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Optimization\n",
    "import cvxpy as cp\n",
    "\n",
    "# Database\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "print(f\"PyMC3: {pm.__version__}\")\n",
    "print(f\"ArviZ: {az.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adstock and Saturation Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdstockTransformations:\n",
    "    \"\"\"Marketing transformations for adstock and saturation.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def geometric_adstock(x: np.ndarray, theta: float) -> np.ndarray:\n",
    "        \"\"\"Apply geometric adstock transformation.\n",
    "        \n",
    "        Args:\n",
    "            x: Marketing spend array\n",
    "            theta: Decay rate (0-1), higher = longer carryover\n",
    "        \"\"\"\n",
    "        adstocked = np.zeros_like(x, dtype=float)\n",
    "        adstocked[0] = x[0]\n",
    "        \n",
    "        for t in range(1, len(x)):\n",
    "            adstocked[t] = x[t] + theta * adstocked[t-1]\n",
    "        \n",
    "        return adstocked\n",
    "    \n",
    "    @staticmethod\n",
    "    def delayed_adstock(x: np.ndarray, theta: float, L: int) -> np.ndarray:\n",
    "        \"\"\"Apply delayed adstock with maximum length L.\n",
    "        \n",
    "        Args:\n",
    "            x: Marketing spend array\n",
    "            theta: Decay rate\n",
    "            L: Maximum lag periods\n",
    "        \"\"\"\n",
    "        weights = np.array([theta ** i for i in range(L)])\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        adstocked = np.convolve(x, weights, mode='same')\n",
    "        return adstocked\n",
    "    \n",
    "    @staticmethod\n",
    "    def hill_saturation(x: np.ndarray, K: float, S: float) -> np.ndarray:\n",
    "        \"\"\"Apply Hill saturation curve.\n",
    "        \n",
    "        Args:\n",
    "            x: Marketing spend (adstocked)\n",
    "            K: Half-saturation point\n",
    "            S: Shape parameter (> 0)\n",
    "        \"\"\"\n",
    "        return x ** S / (K ** S + x ** S)\n",
    "    \n",
    "    @staticmethod\n",
    "    def logistic_saturation(x: np.ndarray, k: float, x0: float) -> np.ndarray:\n",
    "        \"\"\"Apply logistic saturation.\n",
    "        \n",
    "        Args:\n",
    "            x: Marketing spend (adstocked)\n",
    "            k: Growth rate\n",
    "            x0: Midpoint\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-k * (x - x0)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_channel(x: np.ndarray, \n",
    "                         adstock_theta: float,\n",
    "                         saturation_K: float,\n",
    "                         saturation_S: float) -> np.ndarray:\n",
    "        \"\"\"Apply full transformation pipeline to channel.\"\"\"\n",
    "        # Apply adstock\n",
    "        adstocked = AdstockTransformations.geometric_adstock(x, adstock_theta)\n",
    "        \n",
    "        # Apply saturation\n",
    "        saturated = AdstockTransformations.hill_saturation(adstocked, saturation_K, saturation_S)\n",
    "        \n",
    "        return saturated\n",
    "\n",
    "\n",
    "# Example: Visualize transformations\n",
    "def visualize_transformations():\n",
    "    \"\"\"Visualize adstock and saturation effects.\"\"\"\n",
    "    \n",
    "    # Generate sample spend data\n",
    "    spend = np.zeros(52)\n",
    "    spend[10] = 100  # Single spike\n",
    "    \n",
    "    # Apply adstock\n",
    "    adstock_low = AdstockTransformations.geometric_adstock(spend, 0.3)\n",
    "    adstock_high = AdstockTransformations.geometric_adstock(spend, 0.7)\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=['Adstock Effect', 'Saturation Curves'])\n",
    "    \n",
    "    # Adstock plot\n",
    "    fig.add_trace(go.Scatter(y=spend, name='Original', line=dict(dash='dot')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=adstock_low, name='Theta=0.3'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=adstock_high, name='Theta=0.7'), row=1, col=2)\n",
    "    \n",
    "    # Saturation plot\n",
    "    x = np.linspace(0, 100, 1000)\n",
    "    hill = AdstockTransformations.hill_saturation(x, K=50, S=2)\n",
    "    fig.add_trace(go.Scatter(x=x, y=hill, name='Hill Saturation'), row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(height=400, showlegend=True)\n",
    "    return fig\n",
    "\n",
    "# fig = visualize_transformations()\n",
    "# fig.show()\n",
    "\n",
    "print(\"Adstock transformations ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bayesian MMM with PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianMMM:\n",
    "    \"\"\"Bayesian Marketing Mix Model using PyMC3.\"\"\"\n",
    "    \n",
    "    def __init__(self, channel_names: List[str]):\n",
    "        self.channel_names = channel_names\n",
    "        self.model = None\n",
    "        self.trace = None\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def build_model(self, \n",
    "                   y: np.ndarray,\n",
    "                   X_media: np.ndarray,\n",
    "                   X_control: Optional[np.ndarray] = None) -> pm.Model:\n",
    "        \"\"\"Build Bayesian MMM model.\n",
    "        \n",
    "        Args:\n",
    "            y: Target variable (sales, conversions, etc.)\n",
    "            X_media: Media spend matrix (n_periods x n_channels)\n",
    "            X_control: Control variables (seasonality, events, etc.)\n",
    "        \"\"\"\n",
    "        \n",
    "        n_channels = X_media.shape[1]\n",
    "        n_periods = len(y)\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            # Priors for adstock parameters (one per channel)\n",
    "            theta = pm.Beta('theta', alpha=2, beta=2, shape=n_channels)\n",
    "            \n",
    "            # Priors for saturation parameters\n",
    "            K = pm.HalfNormal('K', sigma=1, shape=n_channels)\n",
    "            S = pm.HalfNormal('S', sigma=1, shape=n_channels)\n",
    "            \n",
    "            # Transform media variables\n",
    "            media_adstocked = pm.Deterministic(\n",
    "                'media_adstocked',\n",
    "                tt.stack([self._geometric_adstock_theano(X_media[:, i], theta[i]) \n",
    "                         for i in range(n_channels)], axis=1)\n",
    "            )\n",
    "            \n",
    "            media_transformed = pm.Deterministic(\n",
    "                'media_transformed',\n",
    "                media_adstocked ** S / (K ** S + media_adstocked ** S)\n",
    "            )\n",
    "            \n",
    "            # Priors for coefficients\n",
    "            beta_media = pm.HalfNormal('beta_media', sigma=1, shape=n_channels)\n",
    "            \n",
    "            # Baseline and trend\n",
    "            intercept = pm.Normal('intercept', mu=y.mean(), sigma=y.std())\n",
    "            trend = pm.Normal('trend', mu=0, sigma=0.1)\n",
    "            \n",
    "            # Control variables (if provided)\n",
    "            if X_control is not None:\n",
    "                beta_control = pm.Normal('beta_control', mu=0, sigma=1, \n",
    "                                        shape=X_control.shape[1])\n",
    "                control_contrib = pm.math.dot(X_control, beta_control)\n",
    "            else:\n",
    "                control_contrib = 0\n",
    "            \n",
    "            # Linear combination\n",
    "            time_trend = trend * np.arange(n_periods)\n",
    "            media_contrib = pm.math.dot(media_transformed, beta_media)\n",
    "            \n",
    "            mu = intercept + time_trend + media_contrib + control_contrib\n",
    "            \n",
    "            # Likelihood\n",
    "            sigma = pm.HalfNormal('sigma', sigma=y.std())\n",
    "            likelihood = pm.Normal('y', mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def _geometric_adstock_theano(self, x, theta):\n",
    "        \"\"\"Geometric adstock in Theano for PyMC3.\"\"\"\n",
    "        \n",
    "        def adstock_step(x_t, adstock_prev, theta):\n",
    "            adstock_t = x_t + theta * adstock_prev\n",
    "            return adstock_t\n",
    "        \n",
    "        adstock, _ = theano.scan(\n",
    "            fn=adstock_step,\n",
    "            sequences=x,\n",
    "            outputs_info=tt.zeros(1),\n",
    "            non_sequences=theta\n",
    "        )\n",
    "        \n",
    "        return adstock.flatten()\n",
    "    \n",
    "    def fit(self, draws: int = 2000, tune: int = 1000, \n",
    "           chains: int = 2, target_accept: float = 0.9):\n",
    "        \"\"\"Fit the Bayesian MMM model.\"\"\"\n",
    "        \n",
    "        self.logger.info(\"Starting MCMC sampling\")\n",
    "        \n",
    "        with self.model:\n",
    "            self.trace = pm.sample(\n",
    "                draws=draws,\n",
    "                tune=tune,\n",
    "                chains=chains,\n",
    "                target_accept=target_accept,\n",
    "                return_inferencedata=True,\n",
    "                cores=chains\n",
    "            )\n",
    "        \n",
    "        self.logger.info(\"Sampling complete\")\n",
    "        return self.trace\n",
    "    \n",
    "    def get_channel_contributions(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate channel contributions to total sales.\"\"\"\n",
    "        \n",
    "        # Extract posterior means\n",
    "        beta_media = self.trace.posterior['beta_media'].mean(dim=['chain', 'draw']).values\n",
    "        media_transformed = self.trace.posterior['media_transformed'].mean(dim=['chain', 'draw']).values\n",
    "        \n",
    "        # Calculate contributions\n",
    "        contributions = media_transformed * beta_media\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            contributions,\n",
    "            columns=self.channel_names\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_roas(self, X_media: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Return on Ad Spend (ROAS) for each channel.\"\"\"\n",
    "        \n",
    "        contributions = self.get_channel_contributions()\n",
    "        total_contribution = contributions.sum(axis=0)\n",
    "        total_spend = pd.Series(X_media.sum(axis=0), index=self.channel_names)\n",
    "        \n",
    "        roas = total_contribution / total_spend\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'channel': self.channel_names,\n",
    "            'total_spend': total_spend.values,\n",
    "            'total_contribution': total_contribution.values,\n",
    "            'roas': roas.values\n",
    "        }).sort_values('roas', ascending=False)\n",
    "    \n",
    "    def plot_diagnostics(self):\n",
    "        \"\"\"Plot model diagnostics.\"\"\"\n",
    "        \n",
    "        # Trace plots\n",
    "        az.plot_trace(self.trace, var_names=['beta_media', 'theta'])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Posterior plots\n",
    "        az.plot_posterior(self.trace, var_names=['beta_media'], ref_val=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Save trained model.\"\"\"\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'trace': self.trace,\n",
    "                'channel_names': self.channel_names\n",
    "            }, f)\n",
    "        self.logger.info(f\"Model saved to {filepath}\")\n",
    "\n",
    "\n",
    "print(\"Bayesian MMM class ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical MMM for Geo/Segment Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalMMM:\n",
    "    \"\"\"Hierarchical Bayesian MMM for multiple geos or segments.\"\"\"\n",
    "    \n",
    "    def __init__(self, channel_names: List[str], geo_names: List[str]):\n",
    "        self.channel_names = channel_names\n",
    "        self.geo_names = geo_names\n",
    "        self.model = None\n",
    "        self.trace = None\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def build_hierarchical_model(self,\n",
    "                                y: np.ndarray,\n",
    "                                X_media: np.ndarray,\n",
    "                                geo_idx: np.ndarray) -> pm.Model:\n",
    "        \"\"\"Build hierarchical model across geographies.\n",
    "        \n",
    "        Args:\n",
    "            y: Target variable (all geos concatenated)\n",
    "            X_media: Media spend matrix\n",
    "            geo_idx: Geography index for each observation\n",
    "        \"\"\"\n",
    "        \n",
    "        n_channels = X_media.shape[1]\n",
    "        n_geos = len(self.geo_names)\n",
    "        \n",
    "        with pm.Model() as model:\n",
    "            # Hyperpriors for media coefficients\n",
    "            mu_beta = pm.HalfNormal('mu_beta', sigma=1, shape=n_channels)\n",
    "            sigma_beta = pm.HalfNormal('sigma_beta', sigma=0.5, shape=n_channels)\n",
    "            \n",
    "            # Geo-specific media coefficients\n",
    "            beta_media = pm.Normal('beta_media', \n",
    "                                  mu=mu_beta,\n",
    "                                  sigma=sigma_beta,\n",
    "                                  shape=(n_geos, n_channels))\n",
    "            \n",
    "            # Shared adstock parameters\n",
    "            theta = pm.Beta('theta', alpha=2, beta=2, shape=n_channels)\n",
    "            \n",
    "            # Shared saturation parameters\n",
    "            K = pm.HalfNormal('K', sigma=1, shape=n_channels)\n",
    "            S = pm.HalfNormal('S', sigma=1, shape=n_channels)\n",
    "            \n",
    "            # Transform media (shared transformations)\n",
    "            media_transformed = tt.zeros_like(X_media)\n",
    "            for i in range(n_channels):\n",
    "                adstocked = self._geometric_adstock_theano(X_media[:, i], theta[i])\n",
    "                media_transformed = tt.set_subtensor(\n",
    "                    media_transformed[:, i],\n",
    "                    adstocked ** S[i] / (K[i] ** S[i] + adstocked ** S[i])\n",
    "                )\n",
    "            \n",
    "            # Geo-specific intercepts\n",
    "            intercept = pm.Normal('intercept', mu=y.mean(), sigma=y.std(), shape=n_geos)\n",
    "            \n",
    "            # Linear combination\n",
    "            mu = intercept[geo_idx] + tt.sum(\n",
    "                media_transformed * beta_media[geo_idx, :],\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Likelihood\n",
    "            sigma = pm.HalfNormal('sigma', sigma=y.std())\n",
    "            likelihood = pm.Normal('y', mu=mu, sigma=sigma, observed=y)\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "    def _geometric_adstock_theano(self, x, theta):\n",
    "        \"\"\"Geometric adstock in Theano.\"\"\"\n",
    "        \n",
    "        def adstock_step(x_t, adstock_prev, theta):\n",
    "            return x_t + theta * adstock_prev\n",
    "        \n",
    "        adstock, _ = theano.scan(\n",
    "            fn=adstock_step,\n",
    "            sequences=x,\n",
    "            outputs_info=tt.zeros(1),\n",
    "            non_sequences=theta\n",
    "        )\n",
    "        \n",
    "        return adstock.flatten()\n",
    "    \n",
    "    def fit(self, draws: int = 2000, tune: int = 1000, chains: int = 2):\n",
    "        \"\"\"Fit hierarchical model.\"\"\"\n",
    "        \n",
    "        self.logger.info(\"Starting hierarchical MCMC sampling\")\n",
    "        \n",
    "        with self.model:\n",
    "            self.trace = pm.sample(\n",
    "                draws=draws,\n",
    "                tune=tune,\n",
    "                chains=chains,\n",
    "                target_accept=0.9,\n",
    "                return_inferencedata=True\n",
    "            )\n",
    "        \n",
    "        return self.trace\n",
    "    \n",
    "    def get_geo_roas(self) -> pd.DataFrame:\n",
    "        \"\"\"Get ROAS by geography.\"\"\"\n",
    "        \n",
    "        beta_media = self.trace.posterior['beta_media'].mean(dim=['chain', 'draw']).values\n",
    "        \n",
    "        results = []\n",
    "        for geo_idx, geo_name in enumerate(self.geo_names):\n",
    "            for ch_idx, ch_name in enumerate(self.channel_names):\n",
    "                results.append({\n",
    "                    'geo': geo_name,\n",
    "                    'channel': ch_name,\n",
    "                    'coefficient': beta_media[geo_idx, ch_idx]\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"Hierarchical MMM class ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automated Model Selection and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMMValidator:\n",
    "    \"\"\"Automated validation for MMM models.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def time_series_cv(self, \n",
    "                      X: np.ndarray,\n",
    "                      y: np.ndarray,\n",
    "                      model_class,\n",
    "                      n_splits: int = 5) -> Dict:\n",
    "        \"\"\"Time series cross-validation.\"\"\"\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "            self.logger.info(f\"Fold {fold}/{n_splits}\")\n",
    "            \n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Fit model\n",
    "            model = model_class()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_val)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            scores.append({\n",
    "                'fold': fold,\n",
    "                'r2': r2_score(y_val, y_pred),\n",
    "                'mae': mean_absolute_error(y_val, y_pred),\n",
    "                'rmse': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "                'mape': np.mean(np.abs((y_val - y_pred) / y_val)) * 100\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(scores)\n",
    "    \n",
    "    def check_multicollinearity(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate VIF to check multicollinearity.\"\"\"\n",
    "        \n",
    "        vif_data = []\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            vif = variance_inflation_factor(X.values, i)\n",
    "            vif_data.append({\n",
    "                'variable': X.columns[i],\n",
    "                'vif': vif,\n",
    "                'severity': 'High' if vif > 10 else ('Medium' if vif > 5 else 'Low')\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(vif_data).sort_values('vif', ascending=False)\n",
    "    \n",
    "    def residual_analysis(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict:\n",
    "        \"\"\"Analyze model residuals.\"\"\"\n",
    "        \n",
    "        residuals = y_true - y_pred\n",
    "        \n",
    "        # Normality test\n",
    "        _, p_value = stats.normaltest(residuals)\n",
    "        \n",
    "        # Autocorrelation\n",
    "        acf_values = acf(residuals, nlags=20)\n",
    "        \n",
    "        # Homoscedasticity\n",
    "        _, bp_p_value = stats.levene(y_pred, residuals)\n",
    "        \n",
    "        return {\n",
    "            'mean_residual': residuals.mean(),\n",
    "            'std_residual': residuals.std(),\n",
    "            'normality_p_value': p_value,\n",
    "            'is_normal': p_value > 0.05,\n",
    "            'autocorrelation': acf_values,\n",
    "            'homoscedasticity_p_value': bp_p_value\n",
    "        }\n",
    "    \n",
    "    def compare_models(self, models: Dict, X: np.ndarray, y: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Compare multiple model specifications.\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Split data\n",
    "        split_idx = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            self.logger.info(f\"Evaluating {model_name}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            fit_time = time.time() - start_time\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'r2': r2_score(y_test, y_pred),\n",
    "                'mae': mean_absolute_error(y_test, y_pred),\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "                'mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100,\n",
    "                'fit_time': fit_time\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results).sort_values('r2', ascending=False)\n",
    "\n",
    "\n",
    "validator = MMMValidator()\n",
    "print(\"MMM validator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Budget Optimization with Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BudgetOptimizer:\n",
    "    \"\"\"Optimize marketing budget allocation across channels.\"\"\"\n",
    "    \n",
    "    def __init__(self, channel_names: List[str]):\n",
    "        self.channel_names = channel_names\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def optimize_budget(self,\n",
    "                       response_curves: Dict[str, callable],\n",
    "                       total_budget: float,\n",
    "                       min_spend: Optional[Dict[str, float]] = None,\n",
    "                       max_spend: Optional[Dict[str, float]] = None) -> pd.DataFrame:\n",
    "        \"\"\"Optimize budget allocation to maximize total response.\n",
    "        \n",
    "        Args:\n",
    "            response_curves: Dict mapping channel name to response function\n",
    "            total_budget: Total budget to allocate\n",
    "            min_spend: Minimum spend per channel\n",
    "            max_spend: Maximum spend per channel\n",
    "        \"\"\"\n",
    "        \n",
    "        n_channels = len(self.channel_names)\n",
    "        \n",
    "        # Decision variables\n",
    "        spend = cp.Variable(n_channels, nonneg=True)\n",
    "        \n",
    "        # Objective: maximize total response\n",
    "        # Using piecewise linear approximation for response curves\n",
    "        responses = []\n",
    "        for i, channel in enumerate(self.channel_names):\n",
    "            # Approximate response curve\n",
    "            x_points = np.linspace(0, total_budget / n_channels * 2, 100)\n",
    "            y_points = np.array([response_curves[channel](x) for x in x_points])\n",
    "            \n",
    "            # Linear interpolation (piecewise linear)\n",
    "            response = cp.sum([\n",
    "                (y_points[j+1] - y_points[j]) / (x_points[j+1] - x_points[j]) * \n",
    "                cp.maximum(0, cp.minimum(spend[i] - x_points[j], x_points[j+1] - x_points[j]))\n",
    "                for j in range(len(x_points) - 1)\n",
    "            ])\n",
    "            responses.append(response)\n",
    "        \n",
    "        objective = cp.Maximize(cp.sum(responses))\n",
    "        \n",
    "        # Constraints\n",
    "        constraints = [cp.sum(spend) <= total_budget]\n",
    "        \n",
    "        # Min/max spend constraints\n",
    "        if min_spend:\n",
    "            for i, channel in enumerate(self.channel_names):\n",
    "                if channel in min_spend:\n",
    "                    constraints.append(spend[i] >= min_spend[channel])\n",
    "        \n",
    "        if max_spend:\n",
    "            for i, channel in enumerate(self.channel_names):\n",
    "                if channel in max_spend:\n",
    "                    constraints.append(spend[i] <= max_spend[channel])\n",
    "        \n",
    "        # Solve\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        problem.solve()\n",
    "        \n",
    "        if problem.status == 'optimal':\n",
    "            optimal_spend = spend.value\n",
    "            \n",
    "            results = []\n",
    "            for i, channel in enumerate(self.channel_names):\n",
    "                results.append({\n",
    "                    'channel': channel,\n",
    "                    'optimal_spend': optimal_spend[i],\n",
    "                    'expected_response': response_curves[channel](optimal_spend[i]),\n",
    "                    'marginal_roas': self._marginal_roas(response_curves[channel], optimal_spend[i])\n",
    "                })\n",
    "            \n",
    "            return pd.DataFrame(results)\n",
    "        else:\n",
    "            self.logger.error(f\"Optimization failed: {problem.status}\")\n",
    "            return None\n",
    "    \n",
    "    def _marginal_roas(self, response_func: callable, spend: float, delta: float = 1.0) -> float:\n",
    "        \"\"\"Calculate marginal ROAS at given spend level.\"\"\"\n",
    "        return (response_func(spend + delta) - response_func(spend)) / delta\n",
    "    \n",
    "    def scenario_analysis(self,\n",
    "                         response_curves: Dict[str, callable],\n",
    "                         budget_scenarios: List[float]) -> pd.DataFrame:\n",
    "        \"\"\"Analyze optimal allocation across different budget scenarios.\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for budget in budget_scenarios:\n",
    "            optimal = self.optimize_budget(response_curves, budget)\n",
    "            \n",
    "            if optimal is not None:\n",
    "                total_response = optimal['expected_response'].sum()\n",
    "                avg_roas = total_response / budget\n",
    "                \n",
    "                results.append({\n",
    "                    'total_budget': budget,\n",
    "                    'total_response': total_response,\n",
    "                    'average_roas': avg_roas,\n",
    "                    'allocation': optimal.to_dict('records')\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"Budget optimizer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecasting at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMMForecaster:\n",
    "    \"\"\"Forecast future performance using trained MMM.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def forecast_scenarios(self,\n",
    "                          future_media: Dict[str, np.ndarray],\n",
    "                          n_simulations: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"Generate forecasts for different media scenarios.\n",
    "        \n",
    "        Args:\n",
    "            future_media: Dict mapping scenario name to media spend matrix\n",
    "            n_simulations: Number of Monte Carlo simulations\n",
    "        \"\"\"\n",
    "        \n",
    "        forecasts = []\n",
    "        \n",
    "        for scenario_name, X_future in future_media.items():\n",
    "            self.logger.info(f\"Forecasting scenario: {scenario_name}\")\n",
    "            \n",
    "            # Monte Carlo simulation from posterior\n",
    "            predictions = []\n",
    "            for _ in range(n_simulations):\n",
    "                # Sample from posterior\n",
    "                y_pred = self._sample_prediction(X_future)\n",
    "                predictions.append(y_pred)\n",
    "            \n",
    "            predictions = np.array(predictions)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            forecasts.append({\n",
    "                'scenario': scenario_name,\n",
    "                'mean_forecast': predictions.mean(axis=0),\n",
    "                'lower_95': np.percentile(predictions, 2.5, axis=0),\n",
    "                'upper_95': np.percentile(predictions, 97.5, axis=0),\n",
    "                'std': predictions.std(axis=0)\n",
    "            })\n",
    "        \n",
    "        return forecasts\n",
    "    \n",
    "    def _sample_prediction(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sample prediction from posterior distribution.\"\"\"\n",
    "        # Implementation depends on model type\n",
    "        # For Bayesian models, sample from trace\n",
    "        # For frequentist models, use bootstrap\n",
    "        pass\n",
    "    \n",
    "    def what_if_analysis(self,\n",
    "                        baseline_spend: Dict[str, float],\n",
    "                        channel_to_vary: str,\n",
    "                        spend_range: Tuple[float, float],\n",
    "                        n_points: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"Analyze impact of varying spend on one channel.\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        spend_values = np.linspace(spend_range[0], spend_range[1], n_points)\n",
    "        \n",
    "        for spend in spend_values:\n",
    "            # Create scenario\n",
    "            scenario_spend = baseline_spend.copy()\n",
    "            scenario_spend[channel_to_vary] = spend\n",
    "            \n",
    "            # Predict\n",
    "            X_scenario = self._create_feature_matrix(scenario_spend)\n",
    "            y_pred = self.model.predict(X_scenario)\n",
    "            \n",
    "            results.append({\n",
    "                'channel': channel_to_vary,\n",
    "                'spend': spend,\n",
    "                'predicted_sales': y_pred.mean(),\n",
    "                'incremental_sales': y_pred.mean() - baseline_pred\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def _create_feature_matrix(self, spend_dict: Dict[str, float]) -> np.ndarray:\n",
    "        \"\"\"Create feature matrix from spend dictionary.\"\"\"\n",
    "        # Implementation depends on model features\n",
    "        pass\n",
    "\n",
    "\n",
    "print(\"MMM forecaster ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Project: Enterprise MMM Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnterpriseMMM:\n",
    "    \"\"\"End-to-end enterprise MMM platform.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def run_full_pipeline(self,\n",
    "                         data: pd.DataFrame,\n",
    "                         target_col: str,\n",
    "                         media_cols: List[str],\n",
    "                         control_cols: Optional[List[str]] = None) -> Dict:\n",
    "        \"\"\"Execute complete MMM pipeline.\"\"\"\n",
    "        \n",
    "        self.logger.info(\"Starting enterprise MMM pipeline\")\n",
    "        \n",
    "        # 1. Data preparation\n",
    "        self.logger.info(\"Step 1: Data preparation\")\n",
    "        X_media, X_control, y = self._prepare_data(data, target_col, media_cols, control_cols)\n",
    "        \n",
    "        # 2. Transform features (adstock + saturation)\n",
    "        self.logger.info(\"Step 2: Feature engineering\")\n",
    "        X_transformed = self._engineer_features(X_media)\n",
    "        \n",
    "        # 3. Train multiple models\n",
    "        self.logger.info(\"Step 3: Model training\")\n",
    "        self.models = self._train_models(X_transformed, y, X_control)\n",
    "        \n",
    "        # 4. Model validation\n",
    "        self.logger.info(\"Step 4: Model validation\")\n",
    "        validation_results = self._validate_models(X_transformed, y)\n",
    "        \n",
    "        # 5. Select best model\n",
    "        self.logger.info(\"Step 5: Model selection\")\n",
    "        best_model = self._select_best_model(validation_results)\n",
    "        \n",
    "        # 6. Calculate ROI and attribution\n",
    "        self.logger.info(\"Step 6: Attribution analysis\")\n",
    "        attribution = self._calculate_attribution(best_model, X_media, media_cols)\n",
    "        \n",
    "        # 7. Budget optimization\n",
    "        self.logger.info(\"Step 7: Budget optimization\")\n",
    "        optimal_budget = self._optimize_budget(best_model, media_cols)\n",
    "        \n",
    "        # 8. Generate forecasts\n",
    "        self.logger.info(\"Step 8: Forecasting\")\n",
    "        forecasts = self._generate_forecasts(best_model, media_cols)\n",
    "        \n",
    "        # 9. Create reports\n",
    "        self.logger.info(\"Step 9: Report generation\")\n",
    "        reports = self._generate_reports(attribution, optimal_budget, forecasts)\n",
    "        \n",
    "        return {\n",
    "            'best_model': best_model,\n",
    "            'validation': validation_results,\n",
    "            'attribution': attribution,\n",
    "            'optimal_budget': optimal_budget,\n",
    "            'forecasts': forecasts,\n",
    "            'reports': reports\n",
    "        }\n",
    "    \n",
    "    def _prepare_data(self, data: pd.DataFrame, target_col: str,\n",
    "                     media_cols: List[str], control_cols: Optional[List[str]]) -> Tuple:\n",
    "        \"\"\"Prepare and clean data.\"\"\"\n",
    "        \n",
    "        # Extract arrays\n",
    "        y = data[target_col].values\n",
    "        X_media = data[media_cols].values\n",
    "        X_control = data[control_cols].values if control_cols else None\n",
    "        \n",
    "        # Handle missing values\n",
    "        X_media = np.nan_to_num(X_media, 0)\n",
    "        if X_control is not None:\n",
    "            X_control = np.nan_to_num(X_control, 0)\n",
    "        \n",
    "        return X_media, X_control, y\n",
    "    \n",
    "    def _engineer_features(self, X_media: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply adstock and saturation transformations.\"\"\"\n",
    "        \n",
    "        n_channels = X_media.shape[1]\n",
    "        X_transformed = np.zeros_like(X_media, dtype=float)\n",
    "        \n",
    "        # Apply transformations to each channel\n",
    "        for i in range(n_channels):\n",
    "            # Use default parameters or optimize\n",
    "            theta = 0.5  # Can be optimized\n",
    "            K = X_media[:, i].mean()\n",
    "            S = 1.0\n",
    "            \n",
    "            X_transformed[:, i] = AdstockTransformations.transform_channel(\n",
    "                X_media[:, i], theta, K, S\n",
    "            )\n",
    "        \n",
    "        return X_transformed\n",
    "    \n",
    "    def _train_models(self, X: np.ndarray, y: np.ndarray, \n",
    "                     X_control: Optional[np.ndarray]) -> Dict:\n",
    "        \"\"\"Train multiple model specifications.\"\"\"\n",
    "        \n",
    "        models = {}\n",
    "        \n",
    "        # Combine features\n",
    "        if X_control is not None:\n",
    "            X_full = np.hstack([X, X_control])\n",
    "        else:\n",
    "            X_full = X\n",
    "        \n",
    "        # Train different models\n",
    "        models['ridge'] = Ridge(alpha=1.0).fit(X_full, y)\n",
    "        models['lasso'] = Lasso(alpha=0.1).fit(X_full, y)\n",
    "        models['elastic_net'] = ElasticNet(alpha=0.1, l1_ratio=0.5).fit(X_full, y)\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def _validate_models(self, X: np.ndarray, y: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Validate all trained models.\"\"\"\n",
    "        \n",
    "        validator = MMMValidator()\n",
    "        return validator.compare_models(self.models, X, y)\n",
    "    \n",
    "    def _select_best_model(self, validation_results: pd.DataFrame):\n",
    "        \"\"\"Select best performing model.\"\"\"\n",
    "        best_model_name = validation_results.iloc[0]['model']\n",
    "        return self.models[best_model_name]\n",
    "    \n",
    "    def _calculate_attribution(self, model, X_media: np.ndarray, \n",
    "                              media_cols: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Calculate channel attribution.\"\"\"\n",
    "        \n",
    "        # Get coefficients\n",
    "        coefficients = model.coef_[:len(media_cols)]\n",
    "        \n",
    "        # Calculate contributions\n",
    "        contributions = X_media * coefficients\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'channel': media_cols,\n",
    "            'total_contribution': contributions.sum(axis=0),\n",
    "            'avg_contribution': contributions.mean(axis=0),\n",
    "            'coefficient': coefficients\n",
    "        }).sort_values('total_contribution', ascending=False)\n",
    "    \n",
    "    def _optimize_budget(self, model, media_cols: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Optimize budget allocation.\"\"\"\n",
    "        \n",
    "        # Create response curves from model\n",
    "        # This is simplified - real implementation would be more complex\n",
    "        optimizer = BudgetOptimizer(media_cols)\n",
    "        \n",
    "        # Placeholder - would use actual model predictions\n",
    "        return pd.DataFrame({\n",
    "            'channel': media_cols,\n",
    "            'optimal_spend': [100000] * len(media_cols)\n",
    "        })\n",
    "    \n",
    "    def _generate_forecasts(self, model, media_cols: List[str]) -> Dict:\n",
    "        \"\"\"Generate future forecasts.\"\"\"\n",
    "        \n",
    "        # Placeholder\n",
    "        return {'forecast_periods': 12, 'forecasts': []}\n",
    "    \n",
    "    def _generate_reports(self, attribution: pd.DataFrame,\n",
    "                         optimal_budget: pd.DataFrame,\n",
    "                         forecasts: Dict) -> Dict:\n",
    "        \"\"\"Generate executive reports.\"\"\"\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "        MARKETING MIX MODEL SUMMARY\n",
    "        ==========================\n",
    "        \n",
    "        Top Performing Channels:\n",
    "        {attribution.head(3).to_string()}\n",
    "        \n",
    "        Recommended Budget Allocation:\n",
    "        {optimal_budget.to_string()}\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\n",
    "            'executive_summary': summary,\n",
    "            'detailed_attribution': attribution,\n",
    "            'budget_recommendations': optimal_budget\n",
    "        }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# mmm = EnterpriseMMM({'region': 'US'})\n",
    "# results = mmm.run_full_pipeline(\n",
    "#     data=marketing_data,\n",
    "#     target_col='sales',\n",
    "#     media_cols=['tv', 'digital', 'print'],\n",
    "#     control_cols=['seasonality', 'promotions']\n",
    "# )\n",
    "\n",
    "print(\"Enterprise MMM platform ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercises\n",
    "\n",
    "### Exercise 1: Build Bayesian MMM\n",
    "1. Load marketing dataset with 5+ channels\n",
    "2. Apply adstock and saturation transformations\n",
    "3. Build and train Bayesian MMM with PyMC3\n",
    "4. Analyze posterior distributions\n",
    "5. Calculate ROAS by channel\n",
    "\n",
    "### Exercise 2: Hierarchical Modeling\n",
    "1. Prepare multi-geo dataset\n",
    "2. Build hierarchical MMM\n",
    "3. Compare performance across geographies\n",
    "4. Identify geo-specific vs. shared effects\n",
    "\n",
    "### Exercise 3: Budget Optimization\n",
    "1. Extract response curves from trained model\n",
    "2. Set up optimization problem with constraints\n",
    "3. Find optimal budget allocation\n",
    "4. Perform sensitivity analysis\n",
    "5. Generate scenario comparisons\n",
    "\n",
    "### Exercise 4: Production Deployment\n",
    "1. Build automated MMM pipeline\n",
    "2. Implement model versioning\n",
    "3. Create API endpoints for predictions\n",
    "4. Set up monitoring and alerting\n",
    "5. Generate automated reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Documentation\n",
    "- [PyMC3 Documentation](https://docs.pymc.io/)\n",
    "- [ArviZ - Exploratory Analysis of Bayesian Models](https://arviz-devs.github.io/arviz/)\n",
    "- [CVXPY - Convex Optimization](https://www.cvxpy.org/)\n",
    "- [Meta Robyn MMM](https://github.com/facebookexperimental/Robyn)\n",
    "\n",
    "### Papers & Resources\n",
    "- Jin, Y., et al. (2017). Bayesian Methods for Media Mix Modeling\n",
    "- Shapiro, C. (2018). Marketing Attribution Models\n",
    "- Google: Meridian MMM\n",
    "- Chan & Perry: Challenges in Marketing Mix Modeling\n",
    "\n",
    "### Tools\n",
    "- Robyn (Meta): Open-source MMM\n",
    "- LightweightMMM (Google): Bayesian MMM in JAX\n",
    "- PyMC-Marketing: Marketing analytics with PyMC\n",
    "- Orbit: Bayesian time series framework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
